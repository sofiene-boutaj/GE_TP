{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0BUr_7GVHZT"
      },
      "source": [
        "# **GE - TP: Segmentation avec PyTorch**\n",
        "\n",
        "\n",
        "Dans ce TP, nous allons coder un réseau de neurones pour segmenter des tumeurs sur des scan de cerveau.\n",
        "\n",
        "\n",
        "Try comparison with UNet ++ https://github.com/MrGiovanni/UNetPlusPlus\n",
        "or just add residual connections.\n",
        "Add visualization during the training.\n",
        "\n",
        "\n",
        "- Explore functions in Sitk\n",
        "- Define hyperparameters\n",
        "- Dataset split\n",
        "- ConvBatchNorm\n",
        "- How to import from github ?\n",
        "\n",
        "One additional model\n",
        "- either integrating a new model from model, train it and compare\n",
        "- or show benefits from pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB4W-Jw9VHZn"
      },
      "source": [
        "# **1. Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13YDHJHyC8td",
        "outputId": "f8b13ba4-016b-46d5-b187-da3074583af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 28 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.7)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.46.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.utils.tensorboard\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn.model_selection as model_selection\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install SimpleITK\n",
        "import SimpleITK as sitk\n",
        "\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t2qfPU3VHZx"
      },
      "source": [
        "# **2. Database**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO_00VNxVqB_"
      },
      "source": [
        "## 2.a. Télécharger la base de données.\n",
        "\n",
        "Exécutez la cellule suivante pour télécharger la base de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPENhQdf3QrC",
        "outputId": "f22ca5e8-e687-4980-c45a-b8ffb1f1dde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MVADLMI_TP3' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/soniamartinot/GEP1.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j61_jxGrYoAN",
        "outputId": "13e2b7a0-1b2b-4732-c0f1-818230bc073e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MVADLMI_TP3'...\n",
            "remote: Enumerating objects: 105007, done.\u001b[K\n",
            "remote: Total 105007 (delta 0), reused 0 (delta 0), pack-reused 105007\u001b[K\n",
            "Receiving objects: 100% (105007/105007), 1.72 GiB | 42.78 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "Checking out files: 100% (130674/130674), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/soniamartinot/MVADLMI_TP3.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io16YVeDYE0G"
      },
      "source": [
        "## 2.b. Aperçu de la base de données.\n",
        "\n",
        "Les données se trouvent dans le dossier `/GEP1/`.\n",
        "\n",
        "Dans ce dossier, vous trouverez:\n",
        "\n",
        "> Le dossier `origin_data` : contient 4 patients.\n",
        ">- Pour chaque patient, vous trouverez un volume entier par modalité sous format nifti.\n",
        ">- Chaque volume est de taille `(155, 192, 192)`\n",
        "\n",
        "> Le dossier `data` contient 336 patients.\n",
        ">- Les images dans ce dossier ont été pré-traitées et ont maintenant une taille de `(78, 96, 96)`. La taille plus petite rendra l'entraînement des modèles plus rapide et moins gourmand en ressoures.\n",
        ">- Si on considère un patient `BraTS19_EXAMPLE`, son dossier s'appellera `/GEP1/data/BraTS19_EXAMPLE`. Dans ce dossier, vous trouverez des fichiers nifti (`.nii.gz`) pour chaque modalité, et pour chaque coupe selon l'axe Z.\n",
        ">- Il y a 78 coupes par volume, i.e. 78 coupes par modalité.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJZ7vV9UVHZ7"
      },
      "outputs": [],
      "source": [
        "# The data is store in the folder /GEP1/\n",
        "data_path = './GEP1/data/'\n",
        "original_data_path = './GEP1/origin_data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPUuRxOHVHaA"
      },
      "source": [
        "### **i. Contenu de la base de données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSV6BYfEVHaD",
        "outputId": "eec3a18c-cd1e-4424-d2e9-a0c50160eab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content of the folder:\n",
            " ['BraTS19_TCIA01_131_1', 'BraTS19_TCIA10_442_1', 'BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1']\n",
            "Content of a patient's folder:\n",
            " ['BraTS19_TCIA01_131_1_t2.nii.gz', 'BraTS19_TCIA01_131_1_t1ce.nii.gz', 'BraTS19_TCIA01_131_1_seg.nii.gz', 'BraTS19_TCIA01_131_1_t1.nii.gz', 'BraTS19_TCIA01_131_1_flair.nii.gz']\n"
          ]
        }
      ],
      "source": [
        "# Original data\n",
        "print(\"Content of the folder:\\n\", os.listdir(original_data_path))\n",
        "patient = \"BraTS19_TCIA01_131_1\"\n",
        "print(\"Content of a patient's folder:\\n\", os.listdir(original_data_path + patient))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE1SY6hSVHaH",
        "outputId": "35e8bef8-0b7b-4db7-90c1-d08fddce8d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content of the folder ./MVADLMI_TP3/data/ \n",
            ": ['BraTS19_2013_20_1', 'BraTS19_TCIA06_211_1', 'BraTS19_2013_5_1', 'BraTS19_TCIA01_131_1', 'BraTS19_TCIA01_429_1']\n",
            "Number of files for each patient : 390\n",
            "Number of patients in ./MVADLMI_TP3/data/ : 336\n"
          ]
        }
      ],
      "source": [
        "# Processed data\n",
        "files = os.listdir(data_path) # All the files in the folder /GEP1/data/\n",
        "print('Content of the folder {} \\n: {}'.format(data_path, files[:5]))\n",
        "print('Number of files for each patient : {}'.format(len(os.listdir(data_path + files[0])) ))\n",
        "print('Number of patients in {} : {}'.format(data_path, len(files)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JsQbnkhVHaK"
      },
      "source": [
        "### **ii. Contenu du dossier d'un patient**\n",
        "\n",
        "Pour chaque patient, vous trouverez 4 modalités et les masques de segmentation:\n",
        "\n",
        "- t1\n",
        "- t2\n",
        "- flair\n",
        "- t1ce (gado)\n",
        "- seg\n",
        "    \n",
        "Pour chqaue modalité, vous trouverez un fichier pour chaque coupe selon l'axe Z. Chaque patient a **78 coupes** par modalité."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqWxq524VHaM"
      },
      "outputs": [],
      "source": [
        "modalities = ['t1', 't2', 't1ce', 'flair', 'seg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI1kupGTVHaS",
        "outputId": "e9c92799-b817-46bf-e298-98b8cec4803b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BraTS19_2013_20_1_flair_z_77.nii.gz',\n",
              " 'BraTS19_2013_20_1_t1ce_z_10.nii.gz',\n",
              " 'BraTS19_2013_20_1_flair_z_45.nii.gz',\n",
              " 'BraTS19_2013_20_1_t1ce_z_54.nii.gz',\n",
              " 'BraTS19_2013_20_1_t2_z_61.nii.gz',\n",
              " 'BraTS19_2013_20_1_t1_z_5.nii.gz',\n",
              " 'BraTS19_2013_20_1_seg_z_34.nii.gz',\n",
              " 'BraTS19_2013_20_1_t1_z_6.nii.gz',\n",
              " 'BraTS19_2013_20_1_t1ce_z_39.nii.gz',\n",
              " 'BraTS19_2013_20_1_flair_z_67.nii.gz']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "patient = 'BraTS19_2013_20_1'\n",
        "patient_path = os.path.join(data_path, patient)\n",
        "patient_files = os.listdir(patient_path)\n",
        "patient_files[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLQ4JtRjVHaV",
        "outputId": "8a97bccf-c574-4cc6-8df5-208a1b79b072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Z slices: 78\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['BraTS19_2013_20_1_flair_z_75.nii.gz',\n",
              " 'BraTS19_2013_20_1_flair_z_76.nii.gz',\n",
              " 'BraTS19_2013_20_1_flair_z_77.nii.gz',\n",
              " 'BraTS19_2013_20_1_flair_z_8.nii.gz',\n",
              " 'BraTS19_2013_20_1_flair_z_9.nii.gz']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Filter for the Flair modality\n",
        "\"\"\"\n",
        "\n",
        "flair_modality_files = sorted([e for e in patient_files if 'flair' in e])\n",
        "print(\"Number of Z slices:\", len(flair_modality_files))\n",
        "flair_modality_files[-5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmGMQt78VHaY"
      },
      "source": [
        "### **iii. SimpleITK tutorial**\n",
        "\n",
        "On utilise le package Python `SimpleITK` pour lire les fichiers nifti de la base de données.\n",
        "\n",
        "Pour ouvrir une image nifti, il faut utiliser la fonction suivante:\n",
        "\n",
        "        image = sitk.ReadImage(image_path)\n",
        "\n",
        "Grâce à ce package, vous avez accès à des informations pertinentes, physiques ou médicales, sur chaque image:\n",
        "- spacing: `image.GetSpacing()`\n",
        "- direction: `image.GetDirection()`\n",
        "- origine: `image.GetOrigin()`\n",
        "- taille: `image.GetSize()`\n",
        "- metadata: `image.GetMetaDataKeys()`\n",
        "- valeur d'un pixel: `image.GetPixel(pixel_x, pixel_y, pixel_z)`\n",
        "\n",
        "Vous pouvez passer d'une image `sitk` à un array `numpy` grâce à la commande suivante:\n",
        "\n",
        "        array = sitk.GetArrayFromImage(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPDUJ-IhVHaZ",
        "outputId": "52063918-6060-493e-baaa-0e75ac9974c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to the image: ./MVADLMI_TP3/origin_data/BraTS19_CBICA_ANP_1/BraTS19_CBICA_ANP_1_flair.nii.gz\n",
            "Type of the opened image: <class 'SimpleITK.SimpleITK.Image'>\n"
          ]
        }
      ],
      "source": [
        "patient = 'BraTS19_CBICA_ANP_1'\n",
        "\n",
        "# Define the image path\n",
        "z = 3\n",
        "modality = 'flair'\n",
        "patient_folder = os.path.join(original_data_path, patient)\n",
        "image_name = \"{patient}_{modality}.nii.gz\".format(patient=patient, modality=modality)\n",
        "image_path = os.path.join(patient_folder, image_name)\n",
        "print(\"Path to the image:\", image_path)\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(image_path)\n",
        "print(\"Type of the opened image:\", type(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bZqYuD4VHab",
        "outputId": "58906db4-8395-46eb-bb96-0bbf292fef6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Direction : (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
            "Image Spacing : (1.0, 1.0, 1.0)\n",
            "Image Origin : (-0.0, -239.0, 0.0)\n",
            "Image Size : (240, 240, 155)\n",
            "Pixel value: 0\n"
          ]
        }
      ],
      "source": [
        "# Print geometrical information\n",
        "print('Image Direction : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Image Spacing : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Image Origin : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Image Size : {}'.format(\"\"\"Complete here\"\"\"))\n",
        "print('Pixel value:', \"\"\"Complete here\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vADXJEgjVHad",
        "outputId": "18d3b090-1e6d-4b33-837a-e7045963a6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadata :\n",
            "ITK_FileNotes : \n",
            "ITK_original_direction : [UNKNOWN_PRINT_CHARACTERISTICS]\n",
            "\n",
            "ITK_original_spacing : [UNKNOWN_PRINT_CHARACTERISTICS]\n",
            "\n",
            "aux_file : \n",
            "bitpix : 16\n",
            "cal_max : 0\n",
            "cal_min : 0\n",
            "datatype : 4\n",
            "descrip : \n",
            "dim[0] : 3\n",
            "dim[1] : 240\n",
            "dim[2] : 240\n",
            "dim[3] : 155\n",
            "dim[4] : 1\n",
            "dim[5] : 1\n",
            "dim[6] : 1\n",
            "dim[7] : 1\n",
            "dim_info : 0\n",
            "intent_code : 0\n",
            "intent_name : \n",
            "intent_p1 : 0\n",
            "intent_p2 : 0\n",
            "intent_p3 : 0\n",
            "nifti_type : 1\n",
            "pixdim[0] : 0\n",
            "pixdim[1] : 1\n",
            "pixdim[2] : 1\n",
            "pixdim[3] : 1\n",
            "pixdim[4] : 0\n",
            "pixdim[5] : 0\n",
            "pixdim[6] : 0\n",
            "pixdim[7] : 0\n",
            "qform_code : 1\n",
            "qform_code_name : NIFTI_XFORM_SCANNER_ANAT\n",
            "qoffset_x : 0\n",
            "qoffset_y : 239\n",
            "qoffset_z : 0\n",
            "quatern_b : 0\n",
            "quatern_c : 0\n",
            "quatern_d : 1\n",
            "scl_inter : 0\n",
            "scl_slope : 0\n",
            "sform_code : 1\n",
            "sform_code_name : NIFTI_XFORM_SCANNER_ANAT\n",
            "slice_code : 0\n",
            "slice_duration : 0\n",
            "slice_end : 0\n",
            "slice_start : 0\n",
            "srow_x : -1 -0 -0 0\n",
            "srow_y : -0 -1 -0 239\n",
            "srow_z : 0 0 1 0\n",
            "toffset : 0\n",
            "vox_offset : 2880\n",
            "xyzt_units : 2\n"
          ]
        }
      ],
      "source": [
        "# Get all the information in the meta data\n",
        "keys = image.GetMetaDataKeys()\n",
        "print('Metadata :')\n",
        "for key in keys:\n",
        "    print('{} : {}'.format(key, image.GetMetaData(key)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldR6c6E6VHae",
        "outputId": "33d23962-3138-431a-e4df-7880795e0745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type of the image: <class 'numpy.ndarray'>\n",
            "Shape of the image as a numpy array: (155, 240, 240)\n",
            "Value of the first pixel of the numpy array: 0\n"
          ]
        }
      ],
      "source": [
        "# Convert the sitk image\n",
        "array = sitk.GetArrayFromImage(image)\n",
        "print(\"Type of the image:\", type(array)) # Type of the image\n",
        "print(\"Shape of the image as a numpy array:\", array.shape)\n",
        "print(\"Value of the first pixel of the numpy array:\", array[0, 0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcfaqwSVHah"
      },
      "source": [
        "### **iv. Comparaison entre les données originales et pré-traitées.**\n",
        "\n",
        "\n",
        "Afin d'accélérer les temps de calcul pour obtenir de bons résultats plus rapidement, les images d'origine de taille `(155, 240, 240)` ont été pré-traitées selon les étapes suivantes:\n",
        "- Crop les images à la taille `(155, 192, 192)`\n",
        "- Réduire la résolution des images par interpolation d'échelle 0.5 (https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html) jusqu'à une taille de `(78, 96, 96)`\n",
        "- Sauvegarder les coupes de l'axe Z de façon **indépendemment** les unes des autres dans de nouveaux array de taille `(96, 96)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wswI0m1NVHai",
        "outputId": "67df4131-d1b3-47a4-e86b-50a9f9a2e45e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original array shape : (155, 240, 240)\n",
            "Processed array shape : (96, 96)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "patient = 'BraTS19_CBICA_ANP_1'\n",
        "\n",
        "# Define the image path in the original data\n",
        "z = 3\n",
        "modality = 'flair'\n",
        "patient_folder = os.path.join(original_data_path, patient)\n",
        "image_name = \"{patient}_{modality}.nii.gz\".format(patient=patient, modality=modality)\n",
        "image_path = os.path.join(patient_folder, image_name)\n",
        "\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(image_path)\n",
        "\n",
        "orig_array = sitk.GetArrayFromImage(image)\n",
        "\n",
        "print('Original array shape : {}'.format(orig_array.shape))\n",
        "\n",
        "# open corresponding preprocessed data slice\n",
        "patient_folder = os.path.join(data_path, patient)\n",
        "z_slice = 35\n",
        "path = os.path.join(patient_folder, \"{patient}_{modality}_z_{z_slice}.nii.gz\".format(patient=patient, modality=modality, z_slice=z_slice))\n",
        "processed_image = sitk.ReadImage(path)\n",
        "\n",
        "processed_array = sitk.GetArrayFromImage(processed_image)\n",
        "\n",
        "print('Processed array shape : {}'.format(processed_array.shape))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('Original array')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(processed_array, cmap='gray')\n",
        "plt.title('Processed array')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXW-yIHeVHak"
      },
      "source": [
        "### **v. Visualiser toutes les modalités.**\n",
        "\n",
        "\n",
        "Considérons un patient dans le dossier `data`. Plot chaque modalité côte à côte en itérant sur les coupes Z disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7OYGY8_VHal",
        "outputId": "b5b9f6e0-cd21-43ff-eebd-098afc7efca7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x432 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Go over each Z slice\n",
        "for z in range(len(flair_modality_files)):\n",
        "    f, axes = plt.subplots(1, 5, figsize=(20, 6))\n",
        "\n",
        "    # Plot each modality for that slice\n",
        "    for i, modality in enumerate(modalities):\n",
        "        # Fetch the modality-slice file and open using SimpleITK\n",
        "        file_path = data_path + \"{patient}/{patient}_{modality}_z_{z}.nii.gz\".format(patient=patient, modality=modality, z=z)\n",
        "        slice = sitk.GetArrayFromImage(sitk.ReadImage(file_path))\n",
        "\n",
        "        # Plot the slice\n",
        "        axes[i].set_title(modality)\n",
        "        axes[i].imshow(slice, cmap=\"gray\")\n",
        "\n",
        "    plt.suptitle(\"Slice {}/{}\".format(z+1, len(flair_modality_files)), y=0.85)\n",
        "    plt.show()\n",
        "    clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfFJKex5VHan"
      },
      "source": [
        "## 2.c. Création des train, validation et test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWzV-qrfZ0nk"
      },
      "source": [
        "\n",
        "Les train, validation et test sets sont indiqués dans le dossier `/GEP1/datasets`. Pour chaque set, vous trouverez un fichier texte contenant une liste de patients à inclure dans le set.\n",
        "\n",
        "\n",
        "Exécutez le code suivant afin de:\n",
        "*   Charger les train, validation et test sets.\n",
        "*   Afficher les 5 premiers patients du train set.\n",
        "*   Afficher la longueur des train, validation et test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1nxaDK_Z1AS",
        "outputId": "6152edf3-4f55-4bdb-9fa7-94ee9a47dd61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set, first 5 patients : ['BraTS19_CBICA_BHQ_1' 'BraTS19_CBICA_AQV_1' 'BraTS19_CBICA_ATN_1'\n",
            " 'BraTS19_TCIA01_335_1' 'BraTS19_CBICA_ASY_1']\n",
            "\n",
            "Train set length :\t 251\n",
            "Validation set length :\t 42\n",
            "Test set length :\t 42\n"
          ]
        }
      ],
      "source": [
        "datasets_path = './GEP1/datasets/'\n",
        "\n",
        "train_set = np.loadtxt(datasets_path + 'train.txt', dtype=str)\n",
        "validation_set = np.loadtxt(datasets_path + 'val.txt', dtype=str)\n",
        "test_set = np.loadtxt(datasets_path + 'test.txt', dtype=str)\n",
        "\n",
        "# Train_set, validation_set and test_set are list of patients\n",
        "print('Train set, first 5 patients : {}\\n'.format(train_set[:5])) # Print the first 5 patients of train_set\n",
        "print('Train set length :\\t {}'.format(len(train_set)))\n",
        "print('Validation set length :\\t {}'.format(len(validation_set)))\n",
        "print('Test set length :\\t {}'.format(len(test_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcVUj8KuXXfN"
      },
      "source": [
        "# **3. Creation du réseau de neurones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVPBwaDZnFx"
      },
      "source": [
        "Dans cette partie, nous allons coder un [**UNet**](https://arxiv.org/pdf/1505.04597.pdf). Les UNets sont particulièrement utilisés pour des tâches de segmentation dans le domaine de l'imagerie médicale. Vous pouvez étudier son architecture dans la figure suivante.\n",
        "\n",
        "Le UNet a deux principales caractéristiques:\n",
        "\n",
        "1.   La taille de l'image d'entrée est divisée par 2 à chaque bloc par une couche appelée `MaxPooling` dans la partie **encoder** du modèle. dans la partie **decoder**, les features extraites sont progressivement suréchantillonnées par des Transpose Convolution  (`ConvTranspose2d` in PyTorch) jusqu'à retrouver la taille de l'image d'entrée.\n",
        "\n",
        "2.   Afin de conserver des informations de haute résolution, le modèle est doté de **skip-connections** qui passent de l'information entre l'encoder et le decoder.\n",
        "\n",
        "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qDJ20x-8jPJ"
      },
      "source": [
        "## 3.a. Création du réseau\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgpQMSW4W4hX"
      },
      "source": [
        "**Nota bene**: Sur la figure descriptive du UNet, le nombre de canaux évolue de 64 -> 128 -> 256 -> 512 -> 1024 ... Le modèle correspondant nécessite plus de RAM que ce qui est disponible sur colab.\n",
        "\n",
        "En conséquence, nous reproduirons le UNet en commençant par le nombre de canaux 16 puis 32 -> 64 -> 128 -> 256 ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjY5Q--3VHat"
      },
      "source": [
        "### **i. Building blocks**\n",
        "\n",
        "Que fait la fonction `get_activation` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq0jSmv2VHat"
      },
      "outputs": [],
      "source": [
        "def get_activation(activation_type):\n",
        "    activation_type = activation_type.lower()\n",
        "    if hasattr(nn, activation_type):  return getattr(nn, activation_type)()\n",
        "    else:  return nn.ReLU()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_to-nG9VHau"
      },
      "source": [
        ">Complétez la classe `ConvBatchNorm`. Vous aurez besoin de:\n",
        ">- `get_activation`\n",
        ">- `BatchNorm2d`\n",
        ">- `Conv2d`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjI9ZLS1VHaw"
      },
      "outputs": [],
      "source": [
        "class ConvBatchNorm(nn.Module):\n",
        "    \"\"\"This block implements the sequence: (convolution => [BN] => ReLU)\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, activation='ReLU'):\n",
        "        super(ConvBatchNorm, self).__init__()\n",
        "\n",
        "        self.conv = \n",
        "        self.norm =\n",
        "        self.activation = \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        return out_activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er0wWpbUR16Z"
      },
      "outputs": [],
      "source": [
        "test_conv = ConvBatchNorm(1, 64)\n",
        "\n",
        "x = torch.rand(4, 1, 96, 96)\n",
        "y = test_conv(x)\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjCygJq5VHay"
      },
      "source": [
        "Que fait la fonction `_make_nConv` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_lwX9LuVHaz"
      },
      "outputs": [],
      "source": [
        "def _make_nConv(in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "    layers = []\n",
        "    layers.append(ConvBatchNorm(in_channels, out_channels, activation))\n",
        "    for _ in range(nb_Conv-1):\n",
        "        layers.append(ConvBatchNorm(out_channels, out_channels, activation))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_cz-28VHa0"
      },
      "source": [
        ">Complétez les classes:\n",
        ">- `ConvBatchNorm`\n",
        ">- `DownConvBlock`: cette classe sera utilisée pour construire la partie **encoder**  du UNet.\n",
        ">- `UpConvBlock`: cette classe sera utilisée pour construire la partie **decoder** du UNet.\n",
        "\n",
        ">Vous aurez besoin des couches Pytorch suivantes:\n",
        ">- `MaxPool2d`,\n",
        ">- `ConvTransposed2d` ou `Upsample`,\n",
        ">- `ReLU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQJbRxlfZmAb"
      },
      "outputs": [],
      "source": [
        "class DownBlock(nn.Module):\n",
        "    \"\"\"Downscaling with maxpooling and convolutions\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "        super(DownBlock, self).__init__()\n",
        "\n",
        "        self.maxpool =\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return out_nconvs\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2, activation='ReLU'):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.nConvs(input)\n",
        "        return out\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    \"\"\"Upscaling then conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2, activation='ReLU'):\n",
        "        super(UpBlock, self).__init__()\n",
        "\n",
        "        self.up = \n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "    def forward(self, x, skip_x):\n",
        "\n",
        "        return self.nConvs(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi-HtoNlUlwQ"
      },
      "outputs": [],
      "source": [
        "test_down = DownBlock(64, 128, nb_Conv=2)\n",
        "x = torch.rand(4, 64, 96, 96)\n",
        "y = test_down(x)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "test_down = Bottleneck(512, 512, nb_Conv=2)\n",
        "x = torch.rand(4, 512, 96, 96)\n",
        "y = test_down(x)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "test_down = UpBlock(512, 512, nb_Conv=2)\n",
        "x_1 = torch.rand(4, 256, 96, 96)\n",
        "x_skip = torch.rand(4, 256, 192, 192)\n",
        "\n",
        "y = test_down(x_1, x_skip)\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK4PhCrQVHa3"
      },
      "source": [
        "### **ii. UNet architecture**\n",
        "\n",
        "Ici vous utiliserez les building blocks codés précédemment pour construire l'architecture complète du UNet.\n",
        "\n",
        "- Soyez vigilant aux nombres de canaux d'entrée et de sortie de chaque bloc lorsque vous implémentez les skip connections.\n",
        "\n",
        "- Comparez le code suivant avec la figure du UNet. Où sont les `DownConvBlock`, les `UpConvBlock` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi_jPXtGZ1-p"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=4, n_classes=4):\n",
        "        '''\n",
        "        n_channels : number of channels of the input.\n",
        "                        By default 4, because we have 4 modalities\n",
        "        n_labels : number of channels of the ouput.\n",
        "                      By default 4 (3 labels + 1 for the background)\n",
        "        '''\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Question here\n",
        "\n",
        "        self.inc = ConvBatchNorm(n_channels, 64)\n",
        "        self.down1 = \n",
        "        self.down2 =\n",
        "        self.down3 = \n",
        "        self.down4 = \n",
        "\n",
        "        self.Encoder = [self.down1, self.down2, self.down3, self.down4]\n",
        "\n",
        "        self.bottleneck = \n",
        "\n",
        "        self.up1 =\n",
        "        self.up2 =\n",
        "        self.up3 = \n",
        "\n",
        "        self.Decoder = [self.up1, self.up2, self.up3]\n",
        "\n",
        "        self.outc = nn.Sequential(nn.ConvTranspose2d(64, 64,\n",
        "                                                     kernel_size=3, stride=2,\n",
        "                                                     padding=1, output_padding=1),\n",
        "                                  nn.Conv2d(64, self.n_classes, kernel_size=3, stride=1, padding=1)\n",
        "                                  )\n",
        "        self.last_activation = get_activation('Softmax')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward\n",
        "        skip_inputs = []\n",
        "        x = self.inc(x)\n",
        "\n",
        "        # Forward through encoder\n",
        "        for i, block in enumerate(self.Encoder):\n",
        "\n",
        "            x = block(x)\n",
        "            skip_inputs += [x]\n",
        "            print(x.shape)\n",
        "\n",
        "        # We are at the bottleneck.\n",
        "        bottleneck = self.bottleneck(x)\n",
        "\n",
        "        # Forward through decoder\n",
        "        skip_inputs.reverse()\n",
        "\n",
        "        decoded = bottleneck\n",
        "        for i, block in enumerate(self.Decoder):\n",
        "\n",
        "            # Concat with skipconnections\n",
        "            skipped = skip_inputs[i+1]\n",
        "            print(skipped.shape, decoded.shape)\n",
        "            decoded = block(decoded, skipped)\n",
        "\n",
        "        out = self.last_activation(self.outc(decoded))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1w9PhDYbgFi"
      },
      "outputs": [],
      "source": [
        "test_unet = UNet()\n",
        "x = torch.rand(4, 4, 96, 96)\n",
        "y = test_unet(x)\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtCpyZv8t8L"
      },
      "source": [
        "## 3.b. Analyse du modèle.\n",
        "\n",
        "> Pour étudier et débugger le modèle, vous pouvez lui donner en entrée un tensor random de taille `(1, 4, 96, 96)` (batch size, number of modalites, image shape) avec la fonction `torch.rand`.\n",
        "\n",
        "> La taille de la sortie du réseau doit être la même que celle de l'image d'entrée.\n",
        "\n",
        "> Pour mieux débugger, il vous faudra peut être modifier votre code pour affichier les tailles des sorties de chaque couche du réseau .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktk3C0AWapYk",
        "outputId": "12042b44-c149-4128-c2db-bc84ebc8ed71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet(\n",
            "  (inc): ConvBatchNorm(\n",
            "    (conv): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (activation): ReLU()\n",
            "  )\n",
            "  (down1): DownBlock(\n",
            "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down2): DownBlock(\n",
            "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down3): DownBlock(\n",
            "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down4): DownBlock(\n",
            "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bottleneck): Bottleneck(\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (last): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "  )\n",
            "  (up1): UpBlock(\n",
            "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up2): UpBlock(\n",
            "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up3): UpBlock(\n",
            "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (nConvs): Sequential(\n",
            "      (0): ConvBatchNorm(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (1): ConvBatchNorm(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (outc): Sequential(\n",
            "    (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (1): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (last_activation): ReLU()\n",
            ")\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        }
      ],
      "source": [
        "model = UNet(n_channels=4, n_classes=4)\n",
        "print(model)\n",
        "\n",
        "# Image of size 96*96 with 4 modality + batch size = 1\n",
        "x = torch.rand(1, 4, 96, 96)\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvYD-ZzAoll"
      },
      "source": [
        "# **4. Création du dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-E8AoHtV4PG"
      },
      "source": [
        "## 4.a. Fonctions utiles -  CODE A EXECUTER ET A CACHER\n",
        "\n",
        "\n",
        "Le code suivant est nécessaire pour entraîner correctement le modèle et est déjà codé.\n",
        "\n",
        "Exécutez la cellule suivante. Vous pouvez essayer de comprendre ce que chaque fonction fait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1coYIDpScNmD"
      },
      "outputs": [],
      "source": [
        "end = '.nii.gz'\n",
        "seg_name = '_seg'\n",
        "\n",
        "def load_split(split_folder):\n",
        "    '''\n",
        "        return train, val, test split with loadtxt\n",
        "    '''\n",
        "    train_split = np.loadtxt(os.path.join(\n",
        "        split_folder, 'train.txt'), dtype=str)\n",
        "    val_split = np.loadtxt(os.path.join(split_folder, 'val.txt'), dtype=str)\n",
        "    test_split = np.loadtxt(os.path.join(split_folder, 'test.txt'), dtype=str)\n",
        "    return train_split, val_split, test_split\n",
        "\n",
        "\n",
        "def load_sitk(path):\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
        "\n",
        "\n",
        "def find_z_slice(list_patient, threshold, dataframe):\n",
        "    \"\"\"\n",
        "    For each patient in list_patient, this function returns the list of slices where\n",
        "    the corresponding image is not empty\"\"\"\n",
        "\n",
        "    list_IDs = []\n",
        "    for patient in list_patient:\n",
        "        if threshold > 0:\n",
        "            condition = dataframe[patient].values >= threshold\n",
        "            z_slice = np.where(condition)[0]\n",
        "        else:\n",
        "            z_slice = range(155)\n",
        "        list_IDs += list(set([(patient, int(z//2)) for z in z_slice]))\n",
        "\n",
        "    return list_IDs\n",
        "\n",
        "\n",
        "def generate_IDs(train_split, val_split, test_split,\n",
        "                 tumor_percentage, csv_path, image_size=(240, 240)):\n",
        "\n",
        "    tumor_volume_dataframe = pd.read_csv(csv_path)\n",
        "    threshold = int(tumor_percentage * np.prod(image_size) / 100)\n",
        "\n",
        "    train_IDs, val_IDs, test_IDs = [], [], []\n",
        "    train_IDs = find_z_slice(train_split, threshold, tumor_volume_dataframe)\n",
        "    val_IDs = find_z_slice(val_split, threshold, tumor_volume_dataframe)\n",
        "    test_IDs = find_z_slice(test_split, 0, tumor_volume_dataframe)\n",
        "    return train_IDs, val_IDs, test_IDs\n",
        "\n",
        "\n",
        "def to_var(x, device):\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = torch.from_numpy(x)\n",
        "    x = x.to(device)\n",
        "    return x\n",
        "\n",
        "def to_numpy(x):\n",
        "    if not (isinstance(x, np.ndarray) or x is None):\n",
        "        if x.is_cuda:\n",
        "            x = x.data.cpu()\n",
        "        x = x.numpy()\n",
        "    return x\n",
        "\n",
        "def save_checkpoint(state, save_path):\n",
        "    '''\n",
        "        Save the current model.\n",
        "        If the model is the best model since beginning of the training\n",
        "        it will be copy\n",
        "    '''\n",
        "\n",
        "    if not os.path.isdir(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    epoch = state['epoch']\n",
        "    val_loss = state['val_loss']\n",
        "    filename = save_path + '/' + \\\n",
        "        'model.{:02d}--{:.3f}.pth.tar'.format(epoch, val_loss)\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def print_summary(epoch, i, nb_batch, loss, batch_time,\n",
        "                  average_loss, average_time, mode):\n",
        "    '''\n",
        "        mode = Train or Test\n",
        "    '''\n",
        "    summary = '[' + str(mode) + '] Epoch: [{0}][{1}/{2}]\\t'.format(\n",
        "        epoch, i, nb_batch)\n",
        "\n",
        "    string = ''\n",
        "    string += ('Dice Loss {:.4f} ').format(loss)\n",
        "    string += ('(Average {:.4f}) \\t').format(average_loss)\n",
        "    string += ('Batch Time {:.4f} ').format(batch_time)\n",
        "    string += ('(Average {:.4f}) \\t').format(average_time)\n",
        "\n",
        "    summary += string\n",
        "    print(summary)\n",
        "\n",
        "def plot(irms, masks=None, pred_masks=None):\n",
        "\n",
        "    kwargs = {'cmap': 'gray'}\n",
        "    fig, ax = plt.subplots(2, 3, gridspec_kw={'wspace': 0.15, 'hspace': 0.2,\n",
        "                                              'top': 0.85, 'bottom': 0.1,\n",
        "                                              'left': 0.05, 'right': 0.95},\n",
        "                           figsize=(12, 7))\n",
        "    ax[0, 0].imshow(irms[0, :, :], **kwargs)\n",
        "\n",
        "    if masks is not None:\n",
        "        masks = np.argmax(masks, axis=0)\n",
        "        ax[0, 1].imshow(masks, vmin=0, vmax=3)\n",
        "\n",
        "    if pred_masks is not None:\n",
        "        pred_masks = np.argmax(pred_masks, axis=0)\n",
        "        ax[0, 2].imshow(pred_masks, vmin=0, vmax=3)\n",
        "\n",
        "    for i in range(3):\n",
        "        ax[1, i].imshow(irms[i+1, :, :], **kwargs)\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(3):\n",
        "            ax[i, j].grid(False)\n",
        "            ax[i, j].axis('off')\n",
        "            ax[i, j].set_xticks([])\n",
        "            ax[i, j].set_yticks([])\n",
        "\n",
        "    ax[0, 0].set_title('IRM T1')\n",
        "    ax[1, 0].set_title('IRM Gado')\n",
        "    ax[1, 1].set_title('IRM T2')\n",
        "    ax[1, 2].set_title('IRM Flair')\n",
        "    ax[0, 1].set_title('Ground Truth Seg')\n",
        "    ax[0, 2].set_title('Predicted Seg')\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ehHeKmVHbD"
      },
      "source": [
        "## 4.b. Classe `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GREf0GN5VHbE"
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    'Generates data for torch'\n",
        "\n",
        "    def __init__(self, files_list, data_path, modalities=['t1', 't2', 't1ce', 'flair'], transform=None):\n",
        "        super(SegmentationDataset, self).__init__()\n",
        "        self.files_list = files_list\n",
        "        self.transform = transform\n",
        "        self.data_path = data_path\n",
        "        self.modalities = modalities\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Get a patient given idx'\n",
        "        patient = self.files_list[idx]\n",
        "\n",
        "        # Load the patient's modalities and segmentation masks\n",
        "        irm, mask = self.load(patient)\n",
        "        sample = (irm, mask)\n",
        "\n",
        "        # Apply data transformation\n",
        "        if self.transform:\n",
        "            irm, mask = self.transform(sample)\n",
        "        return (irm, mask, patient)\n",
        "\n",
        "    def load(self, ID):\n",
        "\n",
        "        patient, z_slice = ID\n",
        "        patient_path = os.path.join(self.data_path, patient)\n",
        "\n",
        "        # Get all modalities for the given slice\n",
        "        irm = []\n",
        "        for modality in self.modalities:\n",
        "            file_name = \"{patient}_{modality}_z_{z_slice}.nii.gz\".format(patient=patient, modality=modality, z_slice=z_slice)\n",
        "            path = os.path.join(patient_path, file_name)\n",
        "            irm.append(load_sitk(path))\n",
        "        irm = np.stack(irm, axis=0)\n",
        "\n",
        "        # Get the segmentation mask for the given slice\n",
        "        seg_name = \"{patient}_seg_z_{z_slice}.nii.gz\".format(patient=patient, z_slice=z_slice)\n",
        "        mask_path = os.path.join(patient_path, seg_name)\n",
        "        mask = load_sitk(mask_path)\n",
        "        mask[mask == 4] = 3\n",
        "\n",
        "        # Convert segmentation mask to one-hot encoding\n",
        "        label = 4\n",
        "        mask = mask.astype(np.int16)\n",
        "        mask = np.rollaxis(np.eye(label, dtype=np.uint8)[mask], -1, 0)\n",
        "        return irm, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28f8xpE8VHbG"
      },
      "source": [
        "## 4.c. Génération des différents datasets et des listes de coupes pour chaque patient.\n",
        "\n",
        "`train_IDs`, `val_IDs` et `test_IDs` sont des variables qui correspondent à la variable `files_list` nécessaire lors de la création d'instance de la classe `SegmentationDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIlHj1mhVHbG"
      },
      "outputs": [],
      "source": [
        "# Load the split, generate the IDs list\n",
        "datasets_path ='./GEP1/datasets/'\n",
        "csv_path = './GEP1/data/tumor_count.csv'\n",
        "\n",
        "# The tumour percentage is the percentage of tumour in an image. It's a threshold\n",
        "# that is used when selecting relevant slice indexes in a patient's images.\n",
        "tumour_percentage = 0.5\n",
        "train_split, val_split, test_split = load_split(datasets_path)\n",
        "\n",
        "(train_IDs, val_IDs, test_IDs) = generate_IDs(train_split, val_split, test_split, tumour_percentage, csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug7XxwsMVHbH",
        "outputId": "f12fcc01-b20f-46af-c465-ad51f2f33c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('BraTS19_TCIA01_499_1', 23),\n",
              " ('BraTS19_TCIA01_499_1', 20),\n",
              " ('BraTS19_TCIA01_499_1', 26),\n",
              " ('BraTS19_TCIA01_499_1', 29),\n",
              " ('BraTS19_TCIA01_499_1', 35)]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_IDs[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3x2uH6IVHbJ"
      },
      "source": [
        "## 4.d. Creation des instances de la classe `SegmentationDataset` pour chaque dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLUqBzZ20vJH"
      },
      "outputs": [],
      "source": [
        "# No data augmentation implemented yet.\n",
        "transformation=None\n",
        "\n",
        "train_Dataset = SegmentationDataset(train_IDs, data_path=data_path, transform=transformation)\n",
        "\n",
        "val_Dataset = \"\"\"Complete here\"\"\"\n",
        "\n",
        "test_Dataset = \"\"\"Complete here\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eXLezjAVHbK"
      },
      "source": [
        "The following cell calls for a sample of the training set. Running `train_Dataset[0]` actually calls the `__getitem__` method of the `SegmentationDataset` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvXjeUK4VHbL"
      },
      "outputs": [],
      "source": [
        "input_modalities, segmentation_mask, patient = train_Dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLHlL7QvVHbM",
        "outputId": "f6a4542b-bc68-4f5e-b0ac-08c59dd3948a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the input: (4, 96, 96)\n",
            "Shape of the segmentation masks: (4, 96, 96)\n",
            "Patient identification: BraTS19_CBICA_BHQ_1\n",
            "Selected slice: 41\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of the input:\", input_modalities.shape)\n",
        "print(\"Shape of the segmentation masks:\", segmentation_mask.shape)\n",
        "print(\"Patient identification:\", patient[0])\n",
        "print(\"Selected slice:\", patient[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivb7gvj9VHbO"
      },
      "source": [
        "## 4.e. Création des `DataLoader` utilisés pour l'entraînement.\n",
        "\n",
        "Pour chaque dataset split (train, validation, test), vous devez spécifier:\n",
        "- la taille du batch avec la variable `batch_size`.\n",
        "- s'il faut mélanger le dataset pour donner des batch random de données au modèle avec la varibale `shuffle`.\n",
        "- s'il faut ignorer le dernier batch incomplet, dans le cas où la taille du dataset n'est pas divisible par la taille de batch choisie, avec la variable `drop_last`. Cette variable est particulièrement utile lorsqu'on utilise du multiprocessing (`num_workers` > 1) dans le `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdhN9-SfVHbQ"
      },
      "outputs": [],
      "source": [
        "# Define the batch size\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_Dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "val_loader = \"\"\"Complete here\"\"\"\n",
        "\n",
        "test_loader = \"\"\"Complete here\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y-dKzlyVHbR"
      },
      "source": [
        "# **5. Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbL3St5dVHbT"
      },
      "source": [
        "## 5.a. Loss function, optimizer et hyperparamètres\n",
        "\n",
        "Ici, il vous faudra choisir:\n",
        "- la fonction de perte utilisée pour optimiser les paramètres du modèle(voir [ici](https://pytorch.org/docs/stable/nn.html#loss-functions)),\n",
        "- l'optimizer (voir [ici](https://pytorch.org/docs/stable/optim.html))\n",
        "- tous les hyperparamètres correspondant: learning rate, weight decay ...\n",
        "\n",
        "\n",
        ">Pour commencer, vous pouvez:\n",
        ">- Choisir `Adam` comme optimizer\n",
        ">- Coder votre propre fonction de coût comme étant la Dice loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXuDCj_bJuu_"
      },
      "outputs": [],
      "source": [
        "def dice_loss(input, target):\n",
        "    smooth = 1.\n",
        "    target = target.float()\n",
        "    input = input.float()\n",
        "    input_flat = input.contiguous().view(-1)\n",
        "    target_flat = target.contiguous().view(-1)\n",
        "    intersection = (input_flat * target_flat).sum()\n",
        "    return 1 - ((2. * intersection + smooth) /\n",
        "                (input_flat.pow(2).sum() + target_flat.pow(2).sum() + smooth))\n",
        "\n",
        "def mean_dice_loss(input, target):\n",
        "    channels = list(range(target.shape[1]))\n",
        "    loss = 0\n",
        "    for channel in channels:\n",
        "        dice = dice_loss(input[:, channel, ...],\n",
        "                         target[:, channel, ...])\n",
        "        loss += dice\n",
        "    return loss / len(channels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3T1rsaWVHbW"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "criterion = mean_dice_loss # Choose loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Choose optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccumlRADVHbX"
      },
      "source": [
        "## 5.b. Le modèle\n",
        "\n",
        "Pour créer une instance de la classe `UNet`, vous devez spécifier:\n",
        "- le nombre de canaux d'entrée `n_channels` qui devrait être égal au nombre de modalités considérées (soit 4 modalités)\n",
        "- le nombre de classes de segmentation `n_classes` = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUoS5wUQVHbY"
      },
      "outputs": [],
      "source": [
        "n_modalities = 4\n",
        "n_classes = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o2_ojZwTVHbY",
        "outputId": "ed81b76e-6b71-4366-c591-5944cc409f19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): ConvBatchNorm(\n",
              "    (conv): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "  )\n",
              "  (down1): DownBlock(\n",
              "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): DownBlock(\n",
              "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): DownBlock(\n",
              "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down4): DownBlock(\n",
              "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (bottleneck): Bottleneck(\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (last): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  )\n",
              "  (up1): UpBlock(\n",
              "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2): UpBlock(\n",
              "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3): UpBlock(\n",
              "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    (nConvs): Sequential(\n",
              "      (0): ConvBatchNorm(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (1): ConvBatchNorm(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): Sequential(\n",
              "    (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "    (1): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (last_activation): ReLU()\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.cuda.set_device(3)\n",
        "\n",
        "model = UNet()# Create model\n",
        "model.cuda() # move model to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzLyZKWVHbZ"
      },
      "source": [
        "## 5.c. Training loop pour une seule époque\n",
        "\n",
        "\n",
        "Ici, vous devez compléter la fonciton `train_loop`, qui parcours tout le dataset `loader` une seule fois.\n",
        "\n",
        "Quand le modèle est en entraînement, soit `model.training == True`, il est nécessaire que cette fonction performe aussi la rétropropagation et la mise-à-jour des paramètres du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AHqde7wdTkM"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def train_loop(loader, model, criterion, optimizer, writer, epoch):\n",
        "\n",
        "    logging_mode = 'Train' if model.training else 'Val'\n",
        "\n",
        "\n",
        "    epoch_time_sum, epoch_loss_sum = [], []\n",
        "\n",
        "    for i, sample in enumerate(loader, 1):\n",
        "        start = time.time()\n",
        "        # Take variable\n",
        "        (irms, masks, patients) = sample\n",
        "        # print(irms.shape) # Batch * Number of Modalities * Width * Height\n",
        "\n",
        "        # Put variables to GPU\n",
        "        irms = irms.float().cuda()\n",
        "        masks = masks.float().cuda()\n",
        "\n",
        "        # compute model prediction\n",
        "        pred_masks = \n",
        "\n",
        "        # compute loss\n",
        "        dice_loss = \n",
        "\n",
        "        # If in training mode ...\n",
        "        if model.training:\n",
        "            # Initialize optimizer gradients to zero\n",
        "            \n",
        "            # Perform backpropagation\n",
        "\n",
        "            # Update the model's trainable parameters using the computed gradients\n",
        "\n",
        "\n",
        "        # Compute elapsed time\n",
        "        batch_time = time.time() - start\n",
        "\n",
        "        epoch_time_sum += [batch_time]\n",
        "        epoch_loss_sum += [dice_loss.item()]\n",
        "\n",
        "        average_time = np.mean(epoch_time_sum)\n",
        "        average_loss = np.mean(epoch_loss_sum)\n",
        "\n",
        "        if i % print_frequency == 0:\n",
        "            print_summary(epoch + 1, i, len(loader), dice_loss, batch_time,\n",
        "                          average_loss, average_time, logging_mode)\n",
        "        step = epoch*len(loader) + i\n",
        "        writer.add_scalar(logging_mode + '_dice', dice_loss.item(),step)\n",
        "\n",
        "\n",
        "\n",
        "    writer.add_scalar(logging_mode + '_global_loss', np.mean(epoch_loss_sum), epoch)\n",
        "\n",
        "\n",
        "    # Save some figures to monitor segmentation quality\n",
        "    n_modalities = irms.shape[0]\n",
        "    irms = to_numpy(irms)\n",
        "    masks = to_numpy(masks)\n",
        "    pred_masks = to_numpy(pred_masks)\n",
        "\n",
        "    for batch in range(n_modalities):\n",
        "        fig = plot(irms[batch, ...], masks[batch, ...], pred_masks[batch, ...])\n",
        "        writer.add_figure(logging_mode + str(batch), fig, epoch)\n",
        "    writer.flush()\n",
        "    return np.mean(epoch_loss_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPelDIO4VHbb"
      },
      "source": [
        "## 5.d. Entraînez votre modèle\n",
        " Vous utiliserez **Tensorboard** afin de surveiller que la fonction de loss diminue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiIfIBakVHbc"
      },
      "outputs": [],
      "source": [
        "save_path = \"./GEP1/save/\"\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n",
        "model_path = save_path + 'models/' + session_name + '/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-umPqFHnVHbe"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n",
        "tensorboard_folder = save_path + 'tensorboard_logs/'\n",
        "log_dir = tensorboard_folder + session_name + '/'\n",
        "\n",
        "if not os.path.isdir(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "writer = torch.utils.tensorboard.SummaryWriter(log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8q7mWgOcwnb"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "print_frequency = 10\n",
        "save_frequency = 10\n",
        "save_model = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxyPwfvYw5d5",
        "outputId": "28ce2a03-3715-4f6b-fea5-c643c7541618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******** Epoch [1/6]  ********\n",
            "Test_session_10.06 18h24\n",
            "Training\n",
            "[Train] Epoch: [1][5/106]\tDice Loss 0.2488 (Average 0.2554) \tBatch Time 0.0586 (Average 0.0484) \t\n",
            "[Train] Epoch: [1][10/106]\tDice Loss 0.2303 (Average 0.2524) \tBatch Time 0.0568 (Average 0.0529) \t\n",
            "[Train] Epoch: [1][15/106]\tDice Loss 0.2391 (Average 0.2508) \tBatch Time 0.0580 (Average 0.0545) \t\n",
            "[Train] Epoch: [1][20/106]\tDice Loss 0.2609 (Average 0.2522) \tBatch Time 0.0575 (Average 0.0552) \t\n",
            "[Train] Epoch: [1][25/106]\tDice Loss 0.2221 (Average 0.2506) \tBatch Time 0.0566 (Average 0.0557) \t\n",
            "[Train] Epoch: [1][30/106]\tDice Loss 0.2215 (Average 0.2464) \tBatch Time 0.0575 (Average 0.0561) \t\n",
            "[Train] Epoch: [1][35/106]\tDice Loss 0.2058 (Average 0.2445) \tBatch Time 0.0571 (Average 0.0563) \t\n",
            "[Train] Epoch: [1][40/106]\tDice Loss 0.2444 (Average 0.2418) \tBatch Time 0.0561 (Average 0.0563) \t\n",
            "[Train] Epoch: [1][45/106]\tDice Loss 0.2157 (Average 0.2397) \tBatch Time 0.0577 (Average 0.0564) \t\n",
            "[Train] Epoch: [1][50/106]\tDice Loss 0.2647 (Average 0.2403) \tBatch Time 0.0588 (Average 0.0551) \t\n",
            "[Train] Epoch: [1][55/106]\tDice Loss 0.2195 (Average 0.2386) \tBatch Time 0.0569 (Average 0.0543) \t\n",
            "[Train] Epoch: [1][60/106]\tDice Loss 0.1929 (Average 0.2370) \tBatch Time 0.0315 (Average 0.0532) \t\n",
            "[Train] Epoch: [1][65/106]\tDice Loss 0.1975 (Average 0.2354) \tBatch Time 0.0569 (Average 0.0519) \t\n",
            "[Train] Epoch: [1][70/106]\tDice Loss 0.1898 (Average 0.2334) \tBatch Time 0.0313 (Average 0.0511) \t\n",
            "[Train] Epoch: [1][75/106]\tDice Loss 0.2373 (Average 0.2319) \tBatch Time 0.0306 (Average 0.0499) \t\n",
            "[Train] Epoch: [1][80/106]\tDice Loss 0.2009 (Average 0.2303) \tBatch Time 0.0318 (Average 0.0487) \t\n",
            "[Train] Epoch: [1][85/106]\tDice Loss 0.1886 (Average 0.2288) \tBatch Time 0.0305 (Average 0.0476) \t\n",
            "[Train] Epoch: [1][90/106]\tDice Loss 0.1901 (Average 0.2267) \tBatch Time 0.0391 (Average 0.0468) \t\n",
            "[Train] Epoch: [1][95/106]\tDice Loss 0.2231 (Average 0.2259) \tBatch Time 0.0571 (Average 0.0467) \t\n",
            "[Train] Epoch: [1][100/106]\tDice Loss 0.1938 (Average 0.2245) \tBatch Time 0.0305 (Average 0.0464) \t\n",
            "[Train] Epoch: [1][105/106]\tDice Loss 0.1916 (Average 0.2230) \tBatch Time 0.0579 (Average 0.0470) \t\n",
            "Validation\n",
            "[Val] Epoch: [1][5/19]\tDice Loss 0.3280 (Average 0.2455) \tBatch Time 0.0097 (Average 0.0165) \t\n",
            "[Val] Epoch: [1][10/19]\tDice Loss 0.3541 (Average 0.2678) \tBatch Time 0.0107 (Average 0.0133) \t\n",
            "[Val] Epoch: [1][15/19]\tDice Loss 0.2090 (Average 0.2618) \tBatch Time 0.0108 (Average 0.0123) \t\n",
            "******** Epoch [2/6]  ********\n",
            "Test_session_10.06 18h24\n",
            "Training\n",
            "[Train] Epoch: [2][5/106]\tDice Loss 0.1920 (Average 0.1902) \tBatch Time 0.0569 (Average 0.0586) \t\n",
            "[Train] Epoch: [2][10/106]\tDice Loss 0.1839 (Average 0.1932) \tBatch Time 0.0563 (Average 0.0580) \t\n",
            "[Train] Epoch: [2][15/106]\tDice Loss 0.2102 (Average 0.1945) \tBatch Time 0.0558 (Average 0.0522) \t\n",
            "[Train] Epoch: [2][20/106]\tDice Loss 0.1987 (Average 0.1924) \tBatch Time 0.0585 (Average 0.0536) \t\n",
            "[Train] Epoch: [2][25/106]\tDice Loss 0.1781 (Average 0.1931) \tBatch Time 0.0558 (Average 0.0543) \t\n",
            "[Train] Epoch: [2][30/106]\tDice Loss 0.2122 (Average 0.1940) \tBatch Time 0.0562 (Average 0.0550) \t\n",
            "[Train] Epoch: [2][35/106]\tDice Loss 0.1718 (Average 0.1942) \tBatch Time 0.0578 (Average 0.0553) \t\n",
            "[Train] Epoch: [2][40/106]\tDice Loss 0.1918 (Average 0.1938) \tBatch Time 0.0564 (Average 0.0555) \t\n",
            "[Train] Epoch: [2][45/106]\tDice Loss 0.1732 (Average 0.1933) \tBatch Time 0.0557 (Average 0.0557) \t\n",
            "[Train] Epoch: [2][50/106]\tDice Loss 0.1827 (Average 0.1917) \tBatch Time 0.0556 (Average 0.0559) \t\n",
            "[Train] Epoch: [2][55/106]\tDice Loss 0.1745 (Average 0.1909) \tBatch Time 0.0570 (Average 0.0560) \t\n",
            "[Train] Epoch: [2][60/106]\tDice Loss 0.1832 (Average 0.1898) \tBatch Time 0.0308 (Average 0.0547) \t\n",
            "[Train] Epoch: [2][65/106]\tDice Loss 0.1957 (Average 0.1897) \tBatch Time 0.0310 (Average 0.0541) \t\n",
            "[Train] Epoch: [2][70/106]\tDice Loss 0.1788 (Average 0.1894) \tBatch Time 0.0292 (Average 0.0535) \t\n",
            "[Train] Epoch: [2][75/106]\tDice Loss 0.1782 (Average 0.1887) \tBatch Time 0.0301 (Average 0.0520) \t\n",
            "[Train] Epoch: [2][80/106]\tDice Loss 0.1724 (Average 0.1880) \tBatch Time 0.0290 (Average 0.0506) \t\n",
            "[Train] Epoch: [2][85/106]\tDice Loss 0.1692 (Average 0.1868) \tBatch Time 0.0317 (Average 0.0495) \t\n",
            "[Train] Epoch: [2][90/106]\tDice Loss 0.1748 (Average 0.1856) \tBatch Time 0.0314 (Average 0.0484) \t\n",
            "[Train] Epoch: [2][95/106]\tDice Loss 0.1613 (Average 0.1844) \tBatch Time 0.0306 (Average 0.0476) \t\n",
            "[Train] Epoch: [2][100/106]\tDice Loss 0.1603 (Average 0.1835) \tBatch Time 0.0301 (Average 0.0468) \t\n",
            "[Train] Epoch: [2][105/106]\tDice Loss 0.1691 (Average 0.1823) \tBatch Time 0.0314 (Average 0.0460) \t\n",
            "Validation\n",
            "[Val] Epoch: [2][5/19]\tDice Loss 0.2680 (Average 0.2218) \tBatch Time 0.0096 (Average 0.0117) \t\n",
            "[Val] Epoch: [2][10/19]\tDice Loss 0.3225 (Average 0.2435) \tBatch Time 0.0097 (Average 0.0110) \t\n",
            "[Val] Epoch: [2][15/19]\tDice Loss 0.2247 (Average 0.2448) \tBatch Time 0.0096 (Average 0.0106) \t\n",
            "******** Epoch [3/6]  ********\n",
            "Test_session_10.06 18h24\n",
            "Training\n",
            "[Train] Epoch: [3][5/106]\tDice Loss 0.1545 (Average 0.1634) \tBatch Time 0.0301 (Average 0.0354) \t\n",
            "[Train] Epoch: [3][10/106]\tDice Loss 0.1597 (Average 0.1629) \tBatch Time 0.0316 (Average 0.0331) \t\n",
            "[Train] Epoch: [3][15/106]\tDice Loss 0.1660 (Average 0.1631) \tBatch Time 0.0300 (Average 0.0322) \t\n",
            "[Train] Epoch: [3][20/106]\tDice Loss 0.1656 (Average 0.1625) \tBatch Time 0.0313 (Average 0.0316) \t\n",
            "[Train] Epoch: [3][25/106]\tDice Loss 0.1668 (Average 0.1622) \tBatch Time 0.0303 (Average 0.0314) \t\n",
            "[Train] Epoch: [3][30/106]\tDice Loss 0.1605 (Average 0.1621) \tBatch Time 0.0300 (Average 0.0312) \t\n",
            "[Train] Epoch: [3][35/106]\tDice Loss 0.1602 (Average 0.1620) \tBatch Time 0.0300 (Average 0.0311) \t\n",
            "[Train] Epoch: [3][40/106]\tDice Loss 0.1594 (Average 0.1618) \tBatch Time 0.0299 (Average 0.0312) \t\n",
            "[Train] Epoch: [3][45/106]\tDice Loss 0.1476 (Average 0.1614) \tBatch Time 0.0305 (Average 0.0311) \t\n",
            "[Train] Epoch: [3][50/106]\tDice Loss 0.1618 (Average 0.1610) \tBatch Time 0.0308 (Average 0.0310) \t\n",
            "[Train] Epoch: [3][55/106]\tDice Loss 0.1494 (Average 0.1597) \tBatch Time 0.0325 (Average 0.0310) \t\n",
            "[Train] Epoch: [3][60/106]\tDice Loss 0.1431 (Average 0.1588) \tBatch Time 0.0297 (Average 0.0310) \t\n",
            "[Train] Epoch: [3][65/106]\tDice Loss 0.1521 (Average 0.1580) \tBatch Time 0.0299 (Average 0.0309) \t\n",
            "[Train] Epoch: [3][70/106]\tDice Loss 0.1498 (Average 0.1577) \tBatch Time 0.0294 (Average 0.0309) \t\n",
            "[Train] Epoch: [3][75/106]\tDice Loss 0.1608 (Average 0.1573) \tBatch Time 0.0316 (Average 0.0308) \t\n",
            "[Train] Epoch: [3][80/106]\tDice Loss 0.1613 (Average 0.1571) \tBatch Time 0.0317 (Average 0.0308) \t\n",
            "[Train] Epoch: [3][85/106]\tDice Loss 0.1478 (Average 0.1570) \tBatch Time 0.0419 (Average 0.0311) \t\n",
            "[Train] Epoch: [3][90/106]\tDice Loss 0.1485 (Average 0.1564) \tBatch Time 0.0366 (Average 0.0317) \t\n",
            "[Train] Epoch: [3][95/106]\tDice Loss 0.1470 (Average 0.1563) \tBatch Time 0.0304 (Average 0.0317) \t\n",
            "[Train] Epoch: [3][100/106]\tDice Loss 0.1456 (Average 0.1560) \tBatch Time 0.0329 (Average 0.0317) \t\n",
            "[Train] Epoch: [3][105/106]\tDice Loss 0.1346 (Average 0.1555) \tBatch Time 0.0303 (Average 0.0316) \t\n",
            "Validation\n",
            "[Val] Epoch: [3][5/19]\tDice Loss 0.2690 (Average 0.2150) \tBatch Time 0.0098 (Average 0.0126) \t\n",
            "[Val] Epoch: [3][10/19]\tDice Loss 0.3312 (Average 0.2434) \tBatch Time 0.0094 (Average 0.0111) \t\n",
            "[Val] Epoch: [3][15/19]\tDice Loss 0.1844 (Average 0.2467) \tBatch Time 0.0095 (Average 0.0105) \t\n",
            "******** Epoch [4/6]  ********\n",
            "Test_session_10.06 18h24\n",
            "Training\n",
            "[Train] Epoch: [4][5/106]\tDice Loss 0.1425 (Average 0.1465) \tBatch Time 0.0344 (Average 0.0376) \t\n",
            "[Train] Epoch: [4][10/106]\tDice Loss 0.1455 (Average 0.1450) \tBatch Time 0.0372 (Average 0.0374) \t\n",
            "[Train] Epoch: [4][15/106]\tDice Loss 0.1328 (Average 0.1430) \tBatch Time 0.0296 (Average 0.0352) \t\n",
            "[Train] Epoch: [4][20/106]\tDice Loss 0.1301 (Average 0.1388) \tBatch Time 0.0325 (Average 0.0341) \t\n",
            "[Train] Epoch: [4][25/106]\tDice Loss 0.1188 (Average 0.1352) \tBatch Time 0.0313 (Average 0.0333) \t\n",
            "[Train] Epoch: [4][30/106]\tDice Loss 0.1081 (Average 0.1326) \tBatch Time 0.0378 (Average 0.0331) \t\n",
            "[Train] Epoch: [4][35/106]\tDice Loss 0.1075 (Average 0.1308) \tBatch Time 0.0322 (Average 0.0328) \t\n",
            "[Train] Epoch: [4][40/106]\tDice Loss 0.1138 (Average 0.1296) \tBatch Time 0.0314 (Average 0.0326) \t\n",
            "[Train] Epoch: [4][45/106]\tDice Loss 0.1093 (Average 0.1279) \tBatch Time 0.0314 (Average 0.0324) \t\n",
            "[Train] Epoch: [4][50/106]\tDice Loss 0.1260 (Average 0.1269) \tBatch Time 0.0307 (Average 0.0321) \t\n",
            "[Train] Epoch: [4][55/106]\tDice Loss 0.1104 (Average 0.1256) \tBatch Time 0.0298 (Average 0.0318) \t\n",
            "[Train] Epoch: [4][60/106]\tDice Loss 0.1060 (Average 0.1250) \tBatch Time 0.0313 (Average 0.0317) \t\n",
            "[Train] Epoch: [4][65/106]\tDice Loss 0.1118 (Average 0.1243) \tBatch Time 0.0308 (Average 0.0316) \t\n",
            "[Train] Epoch: [4][70/106]\tDice Loss 0.1192 (Average 0.1240) \tBatch Time 0.0309 (Average 0.0317) \t\n",
            "[Train] Epoch: [4][75/106]\tDice Loss 0.1067 (Average 0.1233) \tBatch Time 0.0297 (Average 0.0315) \t\n",
            "[Train] Epoch: [4][80/106]\tDice Loss 0.1162 (Average 0.1228) \tBatch Time 0.0301 (Average 0.0315) \t\n",
            "[Train] Epoch: [4][85/106]\tDice Loss 0.1214 (Average 0.1224) \tBatch Time 0.0310 (Average 0.0314) \t\n",
            "[Train] Epoch: [4][90/106]\tDice Loss 0.0979 (Average 0.1217) \tBatch Time 0.0300 (Average 0.0314) \t\n",
            "[Train] Epoch: [4][95/106]\tDice Loss 0.1131 (Average 0.1212) \tBatch Time 0.0287 (Average 0.0313) \t\n",
            "[Train] Epoch: [4][100/106]\tDice Loss 0.1085 (Average 0.1208) \tBatch Time 0.0296 (Average 0.0312) \t\n",
            "[Train] Epoch: [4][105/106]\tDice Loss 0.1313 (Average 0.1208) \tBatch Time 0.0301 (Average 0.0312) \t\n",
            "Validation\n",
            "[Val] Epoch: [4][5/19]\tDice Loss 0.1428 (Average 0.2098) \tBatch Time 0.0096 (Average 0.0104) \t\n",
            "[Val] Epoch: [4][10/19]\tDice Loss 0.3111 (Average 0.2328) \tBatch Time 0.0097 (Average 0.0101) \t\n",
            "[Val] Epoch: [4][15/19]\tDice Loss 0.1705 (Average 0.2350) \tBatch Time 0.0097 (Average 0.0100) \t\n",
            "******** Epoch [5/6]  ********\n",
            "Test_session_10.06 18h24\n",
            "Training\n",
            "[Train] Epoch: [5][5/106]\tDice Loss 0.1066 (Average 0.1129) \tBatch Time 0.0292 (Average 0.0423) \t\n",
            "[Train] Epoch: [5][10/106]\tDice Loss 0.1104 (Average 0.1116) \tBatch Time 0.0303 (Average 0.0364) \t\n",
            "[Train] Epoch: [5][15/106]\tDice Loss 0.1094 (Average 0.1126) \tBatch Time 0.0310 (Average 0.0345) \t\n",
            "[Train] Epoch: [5][20/106]\tDice Loss 0.1126 (Average 0.1134) \tBatch Time 0.0310 (Average 0.0339) \t\n",
            "[Train] Epoch: [5][25/106]\tDice Loss 0.1130 (Average 0.1120) \tBatch Time 0.0308 (Average 0.0334) \t\n",
            "[Train] Epoch: [5][30/106]\tDice Loss 0.0990 (Average 0.1103) \tBatch Time 0.0307 (Average 0.0329) \t\n",
            "[Train] Epoch: [5][35/106]\tDice Loss 0.1278 (Average 0.1103) \tBatch Time 0.0313 (Average 0.0326) \t\n",
            "[Train] Epoch: [5][40/106]\tDice Loss 0.0982 (Average 0.1102) \tBatch Time 0.0300 (Average 0.0324) \t\n",
            "[Train] Epoch: [5][45/106]\tDice Loss 0.0974 (Average 0.1098) \tBatch Time 0.0322 (Average 0.0323) \t\n",
            "[Train] Epoch: [5][50/106]\tDice Loss 0.1119 (Average 0.1094) \tBatch Time 0.0297 (Average 0.0320) \t\n",
            "[Train] Epoch: [5][55/106]\tDice Loss 0.0970 (Average 0.1091) \tBatch Time 0.0301 (Average 0.0319) \t\n",
            "[Train] Epoch: [5][60/106]\tDice Loss 0.0876 (Average 0.1086) \tBatch Time 0.0301 (Average 0.0317) \t\n",
            "[Train] Epoch: [5][65/106]\tDice Loss 0.1080 (Average 0.1084) \tBatch Time 0.0306 (Average 0.0316) \t\n",
            "[Train] Epoch: [5][70/106]\tDice Loss 0.1076 (Average 0.1084) \tBatch Time 0.0322 (Average 0.0317) \t\n",
            "[Train] Epoch: [5][75/106]\tDice Loss 0.1064 (Average 0.1081) \tBatch Time 0.0311 (Average 0.0316) \t\n",
            "[Train] Epoch: [5][80/106]\tDice Loss 0.0930 (Average 0.1076) \tBatch Time 0.0307 (Average 0.0315) \t\n",
            "[Train] Epoch: [5][85/106]\tDice Loss 0.1048 (Average 0.1077) \tBatch Time 0.0298 (Average 0.0314) \t\n",
            "[Train] Epoch: [5][90/106]\tDice Loss 0.1159 (Average 0.1077) \tBatch Time 0.0323 (Average 0.0314) \t\n",
            "[Train] Epoch: [5][95/106]\tDice Loss 0.1058 (Average 0.1074) \tBatch Time 0.0324 (Average 0.0314) \t\n",
            "[Train] Epoch: [5][100/106]\tDice Loss 0.1007 (Average 0.1074) \tBatch Time 0.0297 (Average 0.0313) \t\n",
            "[Train] Epoch: [5][105/106]\tDice Loss 0.0988 (Average 0.1073) \tBatch Time 0.0298 (Average 0.0313) \t\n",
            "Validation\n",
            "[Val] Epoch: [5][5/19]\tDice Loss 0.2498 (Average 0.1898) \tBatch Time 0.0097 (Average 0.0178) \t\n",
            "[Val] Epoch: [5][10/19]\tDice Loss 0.2952 (Average 0.2278) \tBatch Time 0.0097 (Average 0.0139) \t\n",
            "[Val] Epoch: [5][15/19]\tDice Loss 0.1555 (Average 0.2182) \tBatch Time 0.0098 (Average 0.0125) \t\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n",
        "    print(session_name)\n",
        "\n",
        "    # train for one epoch\n",
        "    model.train()\n",
        "    print('Training')\n",
        "\n",
        "    train_loss = train_loop(train_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    print('Validation')\n",
        "    with torch.no_grad():   # Disable gradient computation (faster and saves memory)\n",
        "        model.eval()        # Disable Dropout and BatchNormalization\n",
        "\n",
        "        val_loss = train_loop(val_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    if save_model and epoch % save_frequency == 0:\n",
        "        save_checkpoint({'epoch': epoch,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                         'val_loss': val_loss,\n",
        "                         'optimizer': optimizer.state_dict()}, model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5A4lVLHVHbg"
      },
      "source": [
        "#### Look at tensorboard to see the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if7Rn5i9VHbh",
        "outputId": "92981067-9f11-4810-bcff-7dba1e1f5cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.2.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!tensorboard --logdir=./GEP1/save/tensorboard_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqzFo-UD-gYM"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir './GEP1/save/tensorboard_logs/'\n",
        "\n",
        "from tensorboard import notebook\n",
        "notebook.list() # View open TensorBoard instances\n",
        "notebook.display(port=6006, height=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved checkpoint\n",
        "checkpoint = torch.load('model_checkpoint_0.pth')\n",
        "\n",
        "# Load the state_dict into the model\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2kqcqsLqIQm"
      },
      "source": [
        "# **6. Prediction et Evaluation**\n",
        "\n",
        "\n",
        "Après avoir entraîné votre modèle, nous devons maintenant:\n",
        "\n",
        "1.  Utiliser le modèle pour prédire une segmentation.\n",
        "\n",
        "2.  Evaluer les performances du modèles sur le test set.\n",
        "\n",
        "L'évaluation du modèle doit être faite sur le test set, qui n'a pas été vu pendant le training. Le validation set n'était utile que pour contrôler les éventuels problèmes d'overfitting / underfitting.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTIU3BrlhsY"
      },
      "source": [
        "## 6.a. Prediction et retour à l'espace d'origine\n",
        "\n",
        "Dans cet exercice:\n",
        ">- Nous allons charger le modèle pré-entraîné et utiliser la fonction `predict()` pour prédire une segmentation.\n",
        ">- La segmentation prédite aura pour taille `(96, 96, 4)`, pour une coupe selon l'axe Z.\n",
        ">- Afin de faire la comparaison avec les data d'origine, il est nécessaire de retransformer la prédiction en un volume de taille `(155, 240, 240)`.\n",
        "\n",
        "Afin de faire cela, il faudra:\n",
        "\n",
        "- Appliquer la fonction `predict()` à un dataloader. Dans cette étape d'évaluation, il n'y a pas besoin de faire de rétropropagation ni de mettre à jour les paramètres du modèle.\n",
        "- Appliquer la fonction `reconstruct_patient()` afin de reconstruire un volume entier pour un patient donné.\n",
        "- Appliquer la fonction  `get_mask2original_shape()` à la prédiction pour passer d'une taille `(78, 4, 96, 96)` à `(155, 240, 240)`\n",
        "\n",
        "**Questions**\n",
        "- Complétez la fonction `predict()`\n",
        "- Etudiez la fonction `get_mask2original_shape()`. Que font les différentes fonctions internes ? Essayez de deviner les tailles de chaque variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhq4Eat0oJZ1"
      },
      "outputs": [],
      "source": [
        "def predict(loader, model, batch_size=1):\n",
        "    preds = {}\n",
        "    for i, sample in tqdm(enumerate(loader, 1)):\n",
        "        # Take variable and put them to GPU\n",
        "        (irms, masks, patients) = sample\n",
        "\n",
        "        irms = \"\"\"Complete here\"\"\"\n",
        "        masks = \"\"\"Complete here\"\"\"\n",
        "\n",
        "        batch_patient_names, batch_z_slices = patients[0], patients[1]\n",
        "\n",
        "        # compute output\n",
        "        pred_masks = predict(test_loader)\n",
        "\n",
        "        # Put the predictions in a dictionnary with one key being the\n",
        "        # patient and the z slice\n",
        "        n_batch = len(pred_masks)\n",
        "        for j in range(n_batch):\n",
        "            patient, z_slice = batch_patient_names[j], batch_z_slices[j]\n",
        "            name = patient + '_z_' + str(to_numpy(z_slice))\n",
        "            preds[name] = to_numpy(pred_masks[j])\n",
        "    return preds\n",
        "\n",
        "def reconstruct_patient(preds, patient, z_max = 78):\n",
        "    '''\n",
        "    From the dictionnary with prediction find the slice corresponding to\n",
        "    one patient and construct a 3D matrix of shape 77*96*96\n",
        "    '''\n",
        "    X = []\n",
        "    for i in range(z_max):\n",
        "        name = patient + '_z_' + str(i)\n",
        "        array_slice = preds[name]\n",
        "        X.append(array_slice)\n",
        "    X = np.stack(X, axis=0)\n",
        "    return X\n",
        "\n",
        "\n",
        "def get_mask2original_shape(predict_mask):\n",
        "    mask = np.zeros(shape=(155,240, 240))\n",
        "    res = skimage.transform.resize(predict_mask, (155, 4, 192, 192))\n",
        "    res = res > 0.5\n",
        "    res = np.argmax(res, axis=1)\n",
        "    mask[:, 24:-24, 24:-24] = res\n",
        "    mask[mask == 3] = 4\n",
        "    return mask.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "R1ac8F9PsJgG",
        "outputId": "a8d44fe5-9101-4422-d93d-3277e1588db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mask shape: (78, 4, 96, 96)\n",
            "Resized mask shape: (155, 240, 240)\n"
          ]
        }
      ],
      "source": [
        "test_path = original_data_path\n",
        "patients = [os.path.basename(p) for p in glob(test_path + \"*\")]\n",
        "patient = patients[0]\n",
        "\n",
        "model.eval()\n",
        "# Make prediction\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model)\n",
        "\n",
        "# reconstruct the patient's complete volume\n",
        "predict_mask = reconstruct_patient(preds, patient)\n",
        "\n",
        "for i in range(len(predict_mask)):\n",
        "    plt.figure()\n",
        "    plt.title(\"Model prediction - slice {}/{}\".format(i+1, len(predict_mask)+1))\n",
        "    plt.imshow(np.argmax(predict_mask[i, ...], axis=0))\n",
        "    plt.show()\n",
        "    clear_output(wait=True)\n",
        "\n",
        "print(\"Mask shape:\", predict_mask.shape)\n",
        "\n",
        "# Return to original shape\n",
        "predict_mask = get_mask2original_shape(predict_mask)\n",
        "\n",
        "\n",
        "print(\"Resized mask shape:\", predict_mask.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjT3WF0el3yb"
      },
      "source": [
        "## 6.b. Comparaison visuelle\n",
        "\n",
        "\n",
        "Nous allons faire une comparaison qualitative entre la segmentation prédite par le modèle et la segmentation de référence.\n",
        "\n",
        "\n",
        "**Questions**\n",
        "- Chargez la segmentation de référence (dans le dossier `/GEP1/origin_data`) et, en utilisant les fonctions `plt.subplot`, `plt.imshow` et `plt.title`, affichez le masque de segmentation prédit par le modèle, et la segmentation de référence côte à côte.\n",
        "\n",
        "- Etudiez la fonction `numpy2nifti`. Que fait-elle ? Appliquez-là et sauvegardez les masques de segmentation prédits sous format nifti `.nii`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TKSDSeAkaBmC",
        "outputId": "8e13a176-1f1f-446e-e167-f3acbbf9c775"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 936x432 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare visual plot of prediction and original mask\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "patient_folder = os.path.join(test_path, patient)\n",
        "orig_image = sitk.ReadImage(os.path.join(patient_folder, patient  + '_seg.nii.gz' ))\n",
        "orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "z_slice=100\n",
        "for z_slice in range(orig_mask.shape[0]):\n",
        "    plt.figure(figsize=(13, 6))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(orig_mask[z_slice, :,: ], vmin=0, vmax=4)\n",
        "    plt.title('Original mask (slice {})'.format(z_slice))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(predict_mask[z_slice, :,: ], vmin=0, vmax=4)\n",
        "    plt.title('Predicted mask (slice {})'.format(z_slice))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A3-sCKcDtp0"
      },
      "outputs": [],
      "source": [
        "def numpy2sitk(predict_mask, orig_img):\n",
        "    '''\n",
        "    Input : predict_mask of type numpy array\n",
        "            orig_img of type SimpleITK image\n",
        "    Output : new_img of type SimpleITK image\n",
        "    '''\n",
        "    new_img = sitk.GetImageFromArray(predict_mask)\n",
        "    new_img.SetDirection(orig_img.GetDirection())\n",
        "    new_img.SetOrigin(orig_img.GetOrigin())\n",
        "    new_img.SetSpacing(orig_img.GetSpacing())\n",
        "    return new_img\n",
        "\n",
        "predict_img = numpy2sitk(predict_mask, orig_image)\n",
        "path = os.path.join(patient_folder, patient + '_predict_seg.nii.gz')\n",
        "sitk.WriteImage(predict_img, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saALPYgDmFzt"
      },
      "source": [
        "## 6.c. Metrics\n",
        "\n",
        "\n",
        "Nous allons maintenant calculer les métriques d'évaluation pour valider la performance du modèle.\n",
        "\n",
        "Nous allons utiliser 3 métriques:\n",
        "- la sensitivité (aussi appelée le taux de vrais positifs),\n",
        "- la spécificité (aussi appelée le taux de vrais négatifs),\n",
        "- le Dice score (qui est modifier lorsqu'il s'agit de la loss pendant l'entraînement en 1 - Dice score).\n",
        "\n",
        "Nous allons évaluer le modèle selon ces métriques en considérant les 5 patients du dossier `/GEP1/origin_data`. Dans les applications réelles, nous devrions évaluer les métriques sur les patients du test set.\n",
        "\n",
        "**Questions :**\n",
        "- Complétez la fonction `metrics()` afin de calculer le Dice, la sensitivité et la spécificité.\n",
        "- En utilisant les arrays `predict_mask` and `orig_mask` précédents, calculez les métriques. Vous avez juste à appliquer la fonction `evalAllSample()`. Affichez le résultat.\n",
        "- En utilisant une boucle `for`et toutes les fonctions définies dans la partie 3 du TP, calculez les métriques pour les patients du dossier `/GEP1/origin_data`. Affichez les valeurs moyennes de Dice pour chaque catégorie (WT, ET, TC).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebE_L5HE-LXv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def metrics(mask_, gt_):\n",
        "    '''\n",
        "    Taking to binary array of same shape as input\n",
        "    This function compute the confusion matrix and use it to calculate\n",
        "    Dice metrics, Sensitivity and Specificity\n",
        "    Input : mask_, gt_ numpy array of identic shape (only 1 and 0)\n",
        "    Output : List of 3 scores\n",
        "    '''\n",
        "    lnot = np.logical_not\n",
        "    land = np.logical_and\n",
        "\n",
        "    true_positive = np.sum(land((mask_), (gt_)))\n",
        "    false_positive = np.sum(land((mask_), lnot(gt_)))\n",
        "    false_negative = np.sum(land(lnot(mask_), (gt_)))\n",
        "    true_negative = np.sum(land(lnot(mask_), lnot(gt_)))\n",
        "\n",
        "    M = np.array([[true_negative, false_negative],\n",
        "                [false_positive, true_positive]]).astype(np.float64)\n",
        "    metrics = {}\n",
        "    metrics['Sensitivity'] = \"\"\"Complete here\"\"\"\n",
        "    metrics['Specificity'] = \"\"\"Complete here\"\"\"\n",
        "    metrics['Dice'] =  \"\"\"Complete here\"\"\"\n",
        "\n",
        "\n",
        "    # metrics may be NaN if denominator is zero! use np.nanmean() while\n",
        "    # computing average to ignore NaNs.\n",
        "\n",
        "    return [metrics['Dice'], metrics['Sensitivity'], metrics['Specificity']]\n",
        "\n",
        "\n",
        "def evalAllSample(mask_, gt_):\n",
        "    '''\n",
        "    This functions takes as input two numpy arrays with labels between\n",
        "    0, 1, 2 and 4 and calculate the metrics as defined in BraTS data challenge\n",
        "    mask_ and gt_ should be array of int\n",
        "    '''\n",
        "    # whole tumor (labels 1,2,4)\n",
        "    mask_wt, gt_wt = (np.array([0, 1, 1, 0, 1])[mask_],\n",
        "                    np.array([0, 1, 1, 0, 1])[gt_])\n",
        "    wt_metrics = metrics(mask_wt, gt_wt)\n",
        "\n",
        "    # tumor core (labels 1,4)\n",
        "    mask_tc, gt_tc = (np.array([0, 1, 0, 0, 1])[mask_],\n",
        "                    np.array([0, 1, 0, 0, 1])[gt_])\n",
        "    tc_metrics = metrics(mask_tc, gt_tc)\n",
        "\n",
        "    # enhancing tumor (label 4)\n",
        "    mask_et, gt_et = (np.array([0, 0, 0, 0, 1])[mask_],\n",
        "                    np.array([0, 0, 0, 0, 1])[gt_])\n",
        "    et_metrics = metrics(mask_et, gt_et)\n",
        "\n",
        "    return pd.DataFrame({'wt': wt_metrics, 'tc': tc_metrics, 'et': et_metrics},\n",
        "                      index=['Dice', 'Sensitivity', 'Specificity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLCmi1oC-t8u",
        "outputId": "529cc53d-2fc1-4774-915c-caa2e00f4a05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3276it [00:44, 73.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*********** BraTS19_TCIA01_131_1 ***********\n",
            "                   wt        tc        et\n",
            "Dice         0.760534  0.824802  0.745901\n",
            "Sensitivity  0.697605  0.708131  0.611964\n",
            "Specificity  0.999417  0.999988  0.999971\n",
            "\n",
            "\n",
            "*********** BraTS19_TCIA10_442_1 ***********\n",
            "                   wt        tc        et\n",
            "Dice         0.627759  0.304091  0.635871\n",
            "Sensitivity  0.464006  0.179335  0.840426\n",
            "Specificity  0.999813  0.999998  0.999806\n",
            "\n",
            "\n",
            "*********** BraTS19_CBICA_ANP_1 ***********\n",
            "                   wt        tc        et\n",
            "Dice         0.625351  0.587809  0.553887\n",
            "Sensitivity  0.520103  0.637033  0.609440\n",
            "Specificity  0.999272  0.999879  0.999888\n",
            "\n",
            "\n",
            "*********** BraTS19_CBICA_AWV_1 ***********\n",
            "                   wt        tc        et\n",
            "Dice         0.546221  0.605168  0.490454\n",
            "Sensitivity  0.412998  0.437648  0.343872\n",
            "Specificity  0.999731  0.999986  0.999951\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model, batch_size=batch_size)\n",
        "\n",
        "for patient in patients:\n",
        "    # Path to original image\n",
        "    patient_folder = os.path.join(test_path,patient)\n",
        "    # Open image\n",
        "    orig_image = sitk.ReadImage(os.path.join(patient_folder,\n",
        "                                            patient  + '_seg.nii.gz'))\n",
        "    # Convert image to numpy array\n",
        "    orig_mask = \"\"\"Complete here\"\"\"\n",
        "\n",
        "    # Reconstruct the whole patient predicted mask\n",
        "    predict_mask = \"\"\"Complete here\"\"\"\n",
        "    predict_mask = \"\"\"Complete here\"\"\"\n",
        "\n",
        "    print('*********** {} ***********'.format(patient))\n",
        "    # Use the evalAllSamples function to evaluate model\n",
        "    scores = \"\"\"Complete here\"\"\"\n",
        "    print(scores)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    wt_dice_list.append(scores.loc['Dice', 'wt'])\n",
        "    et_dice_list.append(scores.loc['Dice', 'et'])\n",
        "    tc_dice_list.append(scores.loc['Dice', 'tc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlCr9vpxO1-u",
        "outputId": "2c561c18-797f-47ea-c0ec-677a7dd16986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whole Tumor Dice : 0.64\n",
            "Tumor Core Dice : 0.61\n",
            "Enhancing Tumor Dice : 0.58\n"
          ]
        }
      ],
      "source": [
        "print('Whole Tumor Dice : {:.2f}'.format(np.mean(wt_dice_list)))\n",
        "print('Tumor Core Dice : {:.2f}'.format(np.mean(et_dice_list)))\n",
        "print('Enhancing Tumor Dice : {:.2f}'.format(np.mean(tc_dice_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KV5wjPZ_lo7"
      },
      "source": [
        "# **7. Data Augmentation**\n",
        " Dans cette partie, nous allons utiliser des techniques de data augmentation afin d'améliorer les performances du modèle. Parce que les réseaux de neurones convolutifs sont invariants par translation uniquement, l'idée est de créer des échantillons artificiels à partir des données du training set pour que le modèle \"voie\" plus de données et apprenne à mieux généraliser et donc à affiner ses prédictions\n",
        " .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3opEW1YgEGOw"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import scipy.ndimage\n",
        "import numpy as np\n",
        "\n",
        "class AxialFlip(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        choice_x = np.random.randint(0, 2)\n",
        "        choice_y = np.random.randint(0, 2)\n",
        "        irm, mask = sample\n",
        "        new_sample = (self.axialflip(irm, choice_x, choice_y),\n",
        "                      self.axialflip(mask, choice_x, choice_y))\n",
        "        return new_sample\n",
        "\n",
        "    def axialflip(self, array, choice_x, choice_y):\n",
        "        if choice_x == 1:  array = array[:, ::-1, :]\n",
        "        if choice_y == 1:  array = array[:, ::-1, ::-1]\n",
        "        return np.ascontiguousarray(array)\n",
        "\n",
        "class RandomRotation90(object):\n",
        "    '''\n",
        "        Taken from augment_rot90 from MIC-DKFZ/batchgenerators\n",
        "        https://github.com/MIC-DKFZ/batchgenerators/blob/master/batchgenerators/augmentations/spatial_transformations.py\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_rot=(1, 2, 3, 4)):\n",
        "        self.num_rot = num_rot\n",
        "        self.axes = (1,2)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        '''\n",
        "          irm and mask have shape (Modality*Width*Height) and (Label*Width*Height)\n",
        "        '''\n",
        "        num_rot = np.random.choice(self.num_rot)\n",
        "        def f(img):\n",
        "            return np.ascontiguousarray(np.rot90(img, num_rot, self.axes))\n",
        "\n",
        "        irm, mask = sample\n",
        "        new_sample = (f(irm), f(mask))\n",
        "        return new_sample\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, cubic crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size, dim=2):\n",
        "        assert isinstance(output_size, (int, tuple, list))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = dim * (output_size,)\n",
        "        else:\n",
        "            assert len(output_size) == dim\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        irm, mask = sample\n",
        "        _, height, width = irm.shape\n",
        "        i = np.random.randint(0, height - self.output_size[0])\n",
        "        j = np.random.randint(0, width - self.output_size[1])\n",
        "\n",
        "        def f(img):\n",
        "            return img[:, i: i + self.output_size[0], j : j + self.output_size[1]]\n",
        "\n",
        "        new_sample = ( f(irm), f(mask))\n",
        "        return new_sample\n",
        "\n",
        "def RandomTranslation(max_translation=30, transform_matrix=None, debug=False):\n",
        "    translation = np.random.randint(-max_translation, max_translation, 2)\n",
        "    if debug:\n",
        "        return getTranslationMatrix(translation, transform_matrix), (translation)\n",
        "    else:\n",
        "        return getTranslationMatrix(translation, transform_matrix)\n",
        "\n",
        "def RandomRotation(theta_max=20, transform_matrix=None, debug=False):\n",
        "    theta = np.random.uniform(-theta_max, theta_max)\n",
        "    if debug:\n",
        "        return getRotationMatrix(theta, transform_matrix), theta\n",
        "    else:\n",
        "        return getRotationMatrix(theta, transform_matrix)\n",
        "\n",
        "def RandomZoom(zoom_max=0.2, transform_matrix=None, debug=False):\n",
        "    zoom = np.random.uniform(1 - zoom_max, 1 + zoom_max)\n",
        "    if debug:\n",
        "          return getZoomMatrix(zoom, transform_matrix), zoom\n",
        "    else:\n",
        "        return getZoomMatrix(zoom, transform_matrix)\n",
        "\n",
        "def getTranslationMatrix(translation, transform_matrix=None):\n",
        "    '''\n",
        "        2D translation on the axis (0, 1).\n",
        "        Axis 3 is the modality axis\n",
        "        tx: Width shift.\n",
        "        ty: Heigh shift.\n",
        "\n",
        "    '''\n",
        "    shift_matrix = np.array([[1, 0, translation[0]],\n",
        "                            [0, 1, translation[1]],\n",
        "                            [0, 0, 1]])\n",
        "\n",
        "    if transform_matrix is None:\n",
        "        transform_matrix = shift_matrix\n",
        "    else:\n",
        "        transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "def getZoomMatrix(zoom, transform_matrix=None):\n",
        "    '''\n",
        "        Affine Zoom in 2D\n",
        "        zx: Zoom in x direction.\n",
        "        zy: Zoom in y direction\n",
        "    '''\n",
        "    zoom_matrix = np.array([[zoom, 0, 0],\n",
        "                            [0, zoom, 0],\n",
        "                            [0, 0, 1]])\n",
        "    if transform_matrix is None:\n",
        "        transform_matrix = zoom_matrix\n",
        "    else:\n",
        "        transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "def getRotationMatrix(theta, transform_matrix=None):\n",
        "    '''\n",
        "        2D rotation on the axis (0, 1).\n",
        "        Axis 3 is the modality axis\n",
        "        theta: Rotation angle in degrees.\n",
        "    '''\n",
        "    theta = np.deg2rad(theta)\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "                                [np.sin(theta), np.cos(theta), 0],\n",
        "                                [0, 0, 1]])\n",
        "    if transform_matrix is None:\n",
        "        transform_matrix = rotation_matrix\n",
        "    else:\n",
        "        transform_matrix = np.dot(transform_matrix, rotation_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "\n",
        "def apply_affine_transform(x, seg=None, transform_matrix=None, crop_shape=None,\n",
        "                           fill_mode='nearest', cval=0., order=3):\n",
        "    \"\"\"Applies an affine transformation specified by the parameters given.\n",
        "    # Arguments\n",
        "        x: 4D numpy array, single image, multimodalities (Modality*H*W)\n",
        "        fill_mode: Points outside the boundaries of the input\n",
        "            are filled according to the given mode\n",
        "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
        "        cval: Value used for points outside the boundaries\n",
        "            of the input if `mode='constant'`.\n",
        "        order: int, order of interpolation\n",
        "    # Returns\n",
        "        The transformed version of the input.\n",
        "    \"\"\"\n",
        "    if scipy is None:\n",
        "        raise ImportError('Image transformations require SciPy. '\n",
        "                          'Install SciPy.')\n",
        "    if transform_matrix is not None:\n",
        "        channels, h, w = x.shape\n",
        "        transform_matrix = transform_matrix_offset_center(transform_matrix,\n",
        "                                                          h, w)\n",
        "        res = [ scipy.ndimage.affine_transform(x[channel, ...], transform_matrix,\n",
        "                                              order=order, mode=fill_mode, cval=cval)  for channel in range(channels)]\n",
        "        x = np.stack(res, axis=0)\n",
        "\n",
        "        if seg is not None:\n",
        "            labels = seg.shape[0]\n",
        "            res = [scipy.ndimage.affine_transform(seg[label, ...], transform_matrix,\n",
        "                                                                order=order, mode=fill_mode, cval=cval) for label in range(labels)]\n",
        "            seg = np.stack(res, axis=0)\n",
        "            seg[seg > 0.5] = 1\n",
        "            seg[seg < 0.5] = 0\n",
        "            return x, seg\n",
        "    return x\n",
        "\n",
        "def transform_matrix_offset_center(matrix, x, y):\n",
        "    o_x = float(x) / 2 + 0.5\n",
        "    o_y = float(y) / 2 + 0.5\n",
        "    offset_matrix = np.array([[1, 0, o_x],\n",
        "                              [0, 1, o_y],\n",
        "                              [0, 0, 1]])\n",
        "    reset_matrix = np.array([[1, 0, -o_x],\n",
        "                             [0, 1, -o_y],\n",
        "                             [0, 0, 1]])\n",
        "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
        "    return transform_matrix\n",
        "\n",
        "class AffineTransform(object):\n",
        "\n",
        "    def __init__(self, theta=0, max_translation=0, max_zoom=0):\n",
        "        self.theta = theta\n",
        "        self.max_translation = max_translation\n",
        "        self.max_zoom = max_zoom\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        transform_matrix = np.eye(3)\n",
        "        if self.theta > 0:\n",
        "            transform_matrix = RandomRotation(self.theta)\n",
        "        if self.max_translation > 0:\n",
        "            transform_matrix = RandomTranslation(self.max_translation,\n",
        "                                                 transform_matrix)\n",
        "        if self.max_zoom > 0:\n",
        "            transform_matrix = RandomZoom(self.max_zoom,\n",
        "                                          transform_matrix)\n",
        "        new_irm, new_mask = apply_affine_transform(irm, mask, transform_matrix)\n",
        "        return (new_irm, new_mask)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zrwq0EFT-S"
      },
      "source": [
        "## 7.a. Etude de l'augmentation de données.\n",
        "\n",
        "Complétez le code suivant afin de visualiser les effets de différentes techniques d'augmentation de données implémentées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "i4S28vKJ_hXL",
        "outputId": "23aa86ef-c64e-4c1f-9a87-616216a9e066"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3838d0817ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mirms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# irms is a list of a numpy array of shape [Batch * W*H*Modality]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_loader' is not defined"
          ]
        }
      ],
      "source": [
        "k = 3\n",
        "\n",
        "# Create an iterator from the DataLoader\n",
        "val_iter = iter(val_loader)\n",
        "\n",
        "# Get the next batch from the iterator\n",
        "irms, masks, patient = next(val_iter)\n",
        "\n",
        "# irms is a list of a numpy array of shape [Batch * W*H*Modality]\n",
        "irm = irms[0,:].numpy()\n",
        "mask = masks[0,:].numpy()\n",
        "\n",
        "fig = plot(irm, mask)\n",
        "fig.suptitle('Original image')\n",
        "fig.savefig(save_path + 'orig.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNKhDssJoJE"
      },
      "source": [
        "Axial Flip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJIcnxHDJnWQ"
      },
      "outputs": [],
      "source": [
        "flip = \"\"\"Complete here\"\"\"\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = flip((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random Axial Flip')\n",
        "    fig.savefig(save_path + 'Axial_Flip{}.png'.format(k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_pb5eNdJ-sh"
      },
      "source": [
        "90° Rotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZV_gkMPKBoi"
      },
      "outputs": [],
      "source": [
        "random90rotation = \"\"\"Complete here\"\"\"\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = random90rotation((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random 90 degrees Rotation')\n",
        "    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72QMAGP7JTcw"
      },
      "outputs": [],
      "source": [
        "randomcrop = RandomCrop((64, 64))\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = randomcrop((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random crop')\n",
        "    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJsXnMv-Fgsh"
      },
      "source": [
        "Random Rotation with +/- 30°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSjJsOzdFaqc"
      },
      "outputs": [],
      "source": [
        "rotate = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "\n",
        "\n",
        "    (new_irm, new_mask) = rotate((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random rotation')\n",
        "    fig.savefig(save_path + 'Rotation{:.1f}.png'.format(i))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSiqebIFm0d"
      },
      "source": [
        "Random Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZnTTCMUF-TO"
      },
      "outputs": [],
      "source": [
        "translate = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "    new_irm, new_mask  = translate((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random translation')\n",
        "    fig.savefig(save_path + 'Translation_{}.png'.format(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWO-77u0F-1j"
      },
      "source": [
        "Random Zoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q4YHSk8GJcF"
      },
      "outputs": [],
      "source": [
        "zoom = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "    (new_irm, new_mask)  = zoom((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random zoom ')\n",
        "    fig.savefig(save_path + 'Zoom_{}.png'.format(k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fytm3C4GbZU"
      },
      "source": [
        "All transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNzPoFz5GbLP"
      },
      "outputs": [],
      "source": [
        "affine_transform = \"\"\"Complete here\"\"\"\n",
        "\n",
        "for i in range(k):\n",
        "    (new_irm, new_mask)  = affine_transform((irm, mask))\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Rotation Translation Zoom')\n",
        "    fig.savefig(save_path + 'All_transforms{}.png'.format(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaqqV3VeGngd"
      },
      "source": [
        "## 7.b. Entraînement avec data augmentation\n",
        "\n",
        "Relancer un nouvel entraînement avec les techniques d'augmentation de données dans `transformation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqiwTM46GnQm"
      },
      "outputs": [],
      "source": [
        "transforms_list = [AffineTransform(theta=15, max_translation=15, max_zoom=0.3),\n",
        "                   AxialFlip(), RandomRotation90(), RandomCrop((64, 64))\n",
        "                   ]\n",
        "\n",
        "transformation = torchvision.transforms.Compose(transforms_list)\n",
        "\n",
        "\n",
        "train_Dataset = SegmentationDataset(train_IDs, data_path=data_path,\n",
        "                                    transform=transformation\n",
        "                                    )\n",
        "\n",
        "val_Dataset = SegmentationDataset(val_IDs, data_path=data_path,\n",
        "                                  transform=transformation\n",
        "                                  )\n",
        "\n",
        "test_Dataset = SegmentationDataset(test_IDs, data_path=data_path,\n",
        "                                  transform=None\n",
        "                                  )\n",
        "\n",
        "train_loader_data_augment = torch.utils.data.DataLoader(train_Dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "val_loader_data_augment = torch.utils.data.DataLoader(val_Dataset,\n",
        "                                         batch_size=batch_size, drop_last=True)\n",
        "\n",
        "test_loader_data_augment = torch.utils.data.DataLoader(test_Dataset,\n",
        "                                         batch_size=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zsSXipSP3R8"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "image_size = (96, 96)\n",
        "n_modalities = 4\n",
        "n_labels = 4\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "print_frequency = 5\n",
        "save_frequency = 10\n",
        "save_model = True\n",
        "tumor_percentage = 0.5\n",
        "tensorboard = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjSlaLVgQnVL",
        "outputId": "23f5d54b-b456-41de-9905-704f4c14fc67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******** Epoch [1/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [1][5/106]\tDice Loss 0.7400 (Average 0.8418) \tBatch Time 0.1115 (Average 0.1227) \t\n",
            "[Train] Epoch: [1][10/106]\tDice Loss 0.5275 (Average 0.7245) \tBatch Time 0.1099 (Average 0.1162) \t\n",
            "[Train] Epoch: [1][15/106]\tDice Loss 0.3481 (Average 0.6220) \tBatch Time 0.1110 (Average 0.1139) \t\n",
            "[Train] Epoch: [1][20/106]\tDice Loss 0.2147 (Average 0.5325) \tBatch Time 0.1117 (Average 0.1127) \t\n",
            "[Train] Epoch: [1][25/106]\tDice Loss 0.1249 (Average 0.4572) \tBatch Time 0.1100 (Average 0.1122) \t\n",
            "[Train] Epoch: [1][30/106]\tDice Loss 0.0761 (Average 0.3961) \tBatch Time 0.1086 (Average 0.1117) \t\n",
            "[Train] Epoch: [1][35/106]\tDice Loss 0.0503 (Average 0.3480) \tBatch Time 0.1113 (Average 0.1115) \t\n",
            "[Train] Epoch: [1][40/106]\tDice Loss 0.0413 (Average 0.3101) \tBatch Time 0.1108 (Average 0.1112) \t\n",
            "[Train] Epoch: [1][45/106]\tDice Loss 0.0309 (Average 0.2795) \tBatch Time 0.1109 (Average 0.1111) \t\n",
            "[Train] Epoch: [1][50/106]\tDice Loss 0.0265 (Average 0.2546) \tBatch Time 0.1097 (Average 0.1110) \t\n",
            "[Train] Epoch: [1][55/106]\tDice Loss 0.0229 (Average 0.2337) \tBatch Time 0.1112 (Average 0.1110) \t\n",
            "[Train] Epoch: [1][60/106]\tDice Loss 0.0212 (Average 0.2162) \tBatch Time 0.1099 (Average 0.1110) \t\n",
            "[Train] Epoch: [1][65/106]\tDice Loss 0.0206 (Average 0.2011) \tBatch Time 0.1101 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][70/106]\tDice Loss 0.0196 (Average 0.1881) \tBatch Time 0.1115 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][75/106]\tDice Loss 0.0167 (Average 0.1767) \tBatch Time 0.1099 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][80/106]\tDice Loss 0.0172 (Average 0.1667) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][85/106]\tDice Loss 0.0137 (Average 0.1577) \tBatch Time 0.1115 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][90/106]\tDice Loss 0.0134 (Average 0.1498) \tBatch Time 0.1099 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][95/106]\tDice Loss 0.0135 (Average 0.1426) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][100/106]\tDice Loss 0.0113 (Average 0.1361) \tBatch Time 0.1116 (Average 0.1109) \t\n",
            "[Train] Epoch: [1][105/106]\tDice Loss 0.0112 (Average 0.1301) \tBatch Time 0.1100 (Average 0.1109) \t\n",
            "Validation\n",
            "[Val] Epoch: [1][5/19]\tDice Loss 0.0133 (Average 0.0127) \tBatch Time 0.0121 (Average 0.0127) \t\n",
            "[Val] Epoch: [1][10/19]\tDice Loss 0.0118 (Average 0.0125) \tBatch Time 0.0118 (Average 0.0125) \t\n",
            "[Val] Epoch: [1][15/19]\tDice Loss 0.0119 (Average 0.0125) \tBatch Time 0.0117 (Average 0.0125) \t\n",
            "******** Epoch [2/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [2][5/106]\tDice Loss 0.0104 (Average 0.0107) \tBatch Time 0.1100 (Average 0.1126) \t\n",
            "[Train] Epoch: [2][10/106]\tDice Loss 0.0113 (Average 0.0110) \tBatch Time 0.1100 (Average 0.1111) \t\n",
            "[Train] Epoch: [2][15/106]\tDice Loss 0.0109 (Average 0.0108) \tBatch Time 0.1095 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][20/106]\tDice Loss 0.0109 (Average 0.0108) \tBatch Time 0.1113 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][25/106]\tDice Loss 0.0106 (Average 0.0105) \tBatch Time 0.1117 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][30/106]\tDice Loss 0.0102 (Average 0.0104) \tBatch Time 0.1111 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][35/106]\tDice Loss 0.0093 (Average 0.0103) \tBatch Time 0.1102 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][40/106]\tDice Loss 0.0098 (Average 0.0101) \tBatch Time 0.1103 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][45/106]\tDice Loss 0.0085 (Average 0.0100) \tBatch Time 0.1114 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][50/106]\tDice Loss 0.0084 (Average 0.0099) \tBatch Time 0.1113 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][55/106]\tDice Loss 0.0084 (Average 0.0098) \tBatch Time 0.1124 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][60/106]\tDice Loss 0.0092 (Average 0.0097) \tBatch Time 0.1105 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][65/106]\tDice Loss 0.0084 (Average 0.0096) \tBatch Time 0.1087 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][70/106]\tDice Loss 0.0093 (Average 0.0095) \tBatch Time 0.1100 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][75/106]\tDice Loss 0.0080 (Average 0.0094) \tBatch Time 0.1112 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][80/106]\tDice Loss 0.0088 (Average 0.0094) \tBatch Time 0.1122 (Average 0.1106) \t\n",
            "[Train] Epoch: [2][85/106]\tDice Loss 0.0083 (Average 0.0093) \tBatch Time 0.1101 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][90/106]\tDice Loss 0.0082 (Average 0.0092) \tBatch Time 0.1113 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][95/106]\tDice Loss 0.0072 (Average 0.0091) \tBatch Time 0.1083 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][100/106]\tDice Loss 0.0076 (Average 0.0091) \tBatch Time 0.1117 (Average 0.1105) \t\n",
            "[Train] Epoch: [2][105/106]\tDice Loss 0.0071 (Average 0.0090) \tBatch Time 0.1100 (Average 0.1106) \t\n",
            "Validation\n",
            "[Val] Epoch: [2][5/19]\tDice Loss 0.0085 (Average 0.0083) \tBatch Time 0.0124 (Average 0.0134) \t\n",
            "[Val] Epoch: [2][10/19]\tDice Loss 0.0080 (Average 0.0081) \tBatch Time 0.0125 (Average 0.0128) \t\n",
            "[Val] Epoch: [2][15/19]\tDice Loss 0.0072 (Average 0.0081) \tBatch Time 0.0124 (Average 0.0126) \t\n",
            "******** Epoch [3/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [3][5/106]\tDice Loss 0.0078 (Average 0.0075) \tBatch Time 0.1120 (Average 0.1196) \t\n",
            "[Train] Epoch: [3][10/106]\tDice Loss 0.0074 (Average 0.0076) \tBatch Time 0.1081 (Average 0.1148) \t\n",
            "[Train] Epoch: [3][15/106]\tDice Loss 0.0071 (Average 0.0074) \tBatch Time 0.1103 (Average 0.1133) \t\n",
            "[Train] Epoch: [3][20/106]\tDice Loss 0.0072 (Average 0.0074) \tBatch Time 0.1084 (Average 0.1123) \t\n",
            "[Train] Epoch: [3][25/106]\tDice Loss 0.0067 (Average 0.0073) \tBatch Time 0.1114 (Average 0.1119) \t\n",
            "[Train] Epoch: [3][30/106]\tDice Loss 0.0073 (Average 0.0073) \tBatch Time 0.1103 (Average 0.1116) \t\n",
            "[Train] Epoch: [3][35/106]\tDice Loss 0.0069 (Average 0.0073) \tBatch Time 0.1101 (Average 0.1113) \t\n",
            "[Train] Epoch: [3][40/106]\tDice Loss 0.0073 (Average 0.0073) \tBatch Time 0.1119 (Average 0.1111) \t\n",
            "[Train] Epoch: [3][45/106]\tDice Loss 0.0070 (Average 0.0073) \tBatch Time 0.1121 (Average 0.1111) \t\n",
            "[Train] Epoch: [3][50/106]\tDice Loss 0.0071 (Average 0.0073) \tBatch Time 0.1099 (Average 0.1110) \t\n",
            "[Train] Epoch: [3][55/106]\tDice Loss 0.0065 (Average 0.0072) \tBatch Time 0.1066 (Average 0.1109) \t\n",
            "[Train] Epoch: [3][60/106]\tDice Loss 0.0070 (Average 0.0072) \tBatch Time 0.1102 (Average 0.1109) \t\n",
            "[Train] Epoch: [3][65/106]\tDice Loss 0.0056 (Average 0.0071) \tBatch Time 0.1107 (Average 0.1108) \t\n",
            "[Train] Epoch: [3][70/106]\tDice Loss 0.0069 (Average 0.0071) \tBatch Time 0.1100 (Average 0.1108) \t\n",
            "[Train] Epoch: [3][75/106]\tDice Loss 0.0067 (Average 0.0071) \tBatch Time 0.1112 (Average 0.1109) \t\n",
            "[Train] Epoch: [3][80/106]\tDice Loss 0.0065 (Average 0.0071) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [3][85/106]\tDice Loss 0.0067 (Average 0.0070) \tBatch Time 0.1114 (Average 0.1108) \t\n",
            "[Train] Epoch: [3][90/106]\tDice Loss 0.0061 (Average 0.0070) \tBatch Time 0.1115 (Average 0.1109) \t\n",
            "[Train] Epoch: [3][95/106]\tDice Loss 0.0057 (Average 0.0069) \tBatch Time 0.1096 (Average 0.1108) \t\n",
            "[Train] Epoch: [3][100/106]\tDice Loss 0.0060 (Average 0.0069) \tBatch Time 0.1115 (Average 0.1108) \t\n",
            "[Train] Epoch: [3][105/106]\tDice Loss 0.0069 (Average 0.0068) \tBatch Time 0.1116 (Average 0.1108) \t\n",
            "Validation\n",
            "[Val] Epoch: [3][5/19]\tDice Loss 0.0070 (Average 0.0067) \tBatch Time 0.0113 (Average 0.0123) \t\n",
            "[Val] Epoch: [3][10/19]\tDice Loss 0.0067 (Average 0.0067) \tBatch Time 0.0120 (Average 0.0120) \t\n",
            "[Val] Epoch: [3][15/19]\tDice Loss 0.0071 (Average 0.0067) \tBatch Time 0.0117 (Average 0.0119) \t\n",
            "******** Epoch [4/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [4][5/106]\tDice Loss 0.0057 (Average 0.0062) \tBatch Time 0.1098 (Average 0.1212) \t\n",
            "[Train] Epoch: [4][10/106]\tDice Loss 0.0063 (Average 0.0061) \tBatch Time 0.1084 (Average 0.1154) \t\n",
            "[Train] Epoch: [4][15/106]\tDice Loss 0.0051 (Average 0.0060) \tBatch Time 0.1108 (Average 0.1138) \t\n",
            "[Train] Epoch: [4][20/106]\tDice Loss 0.0054 (Average 0.0059) \tBatch Time 0.1112 (Average 0.1128) \t\n",
            "[Train] Epoch: [4][25/106]\tDice Loss 0.0060 (Average 0.0059) \tBatch Time 0.1107 (Average 0.1124) \t\n",
            "[Train] Epoch: [4][30/106]\tDice Loss 0.0064 (Average 0.0059) \tBatch Time 0.1112 (Average 0.1120) \t\n",
            "[Train] Epoch: [4][35/106]\tDice Loss 0.0063 (Average 0.0059) \tBatch Time 0.1113 (Average 0.1118) \t\n",
            "[Train] Epoch: [4][40/106]\tDice Loss 0.0061 (Average 0.0059) \tBatch Time 0.1091 (Average 0.1116) \t\n",
            "[Train] Epoch: [4][45/106]\tDice Loss 0.0052 (Average 0.0059) \tBatch Time 0.1080 (Average 0.1115) \t\n",
            "[Train] Epoch: [4][50/106]\tDice Loss 0.0063 (Average 0.0059) \tBatch Time 0.1116 (Average 0.1114) \t\n",
            "[Train] Epoch: [4][55/106]\tDice Loss 0.0055 (Average 0.0059) \tBatch Time 0.1114 (Average 0.1113) \t\n",
            "[Train] Epoch: [4][60/106]\tDice Loss 0.0051 (Average 0.0058) \tBatch Time 0.1114 (Average 0.1112) \t\n",
            "[Train] Epoch: [4][65/106]\tDice Loss 0.0054 (Average 0.0058) \tBatch Time 0.1101 (Average 0.1112) \t\n",
            "[Train] Epoch: [4][70/106]\tDice Loss 0.0058 (Average 0.0058) \tBatch Time 0.1084 (Average 0.1110) \t\n",
            "[Train] Epoch: [4][75/106]\tDice Loss 0.0054 (Average 0.0058) \tBatch Time 0.1085 (Average 0.1110) \t\n",
            "[Train] Epoch: [4][80/106]\tDice Loss 0.0059 (Average 0.0057) \tBatch Time 0.1101 (Average 0.1109) \t\n",
            "[Train] Epoch: [4][85/106]\tDice Loss 0.0056 (Average 0.0057) \tBatch Time 0.1080 (Average 0.1108) \t\n",
            "[Train] Epoch: [4][90/106]\tDice Loss 0.0056 (Average 0.0057) \tBatch Time 0.1088 (Average 0.1107) \t\n",
            "[Train] Epoch: [4][95/106]\tDice Loss 0.0058 (Average 0.0057) \tBatch Time 0.1085 (Average 0.1105) \t\n",
            "[Train] Epoch: [4][100/106]\tDice Loss 0.0054 (Average 0.0057) \tBatch Time 0.1086 (Average 0.1105) \t\n",
            "[Train] Epoch: [4][105/106]\tDice Loss 0.0057 (Average 0.0057) \tBatch Time 0.1057 (Average 0.1105) \t\n",
            "Validation\n",
            "[Val] Epoch: [4][5/19]\tDice Loss 0.0061 (Average 0.0055) \tBatch Time 0.0118 (Average 0.0125) \t\n",
            "[Val] Epoch: [4][10/19]\tDice Loss 0.0054 (Average 0.0055) \tBatch Time 0.0128 (Average 0.0127) \t\n",
            "[Val] Epoch: [4][15/19]\tDice Loss 0.0050 (Average 0.0054) \tBatch Time 0.0119 (Average 0.0125) \t\n",
            "******** Epoch [5/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [5][5/106]\tDice Loss 0.0051 (Average 0.0055) \tBatch Time 0.1084 (Average 0.1206) \t\n",
            "[Train] Epoch: [5][10/106]\tDice Loss 0.0059 (Average 0.0056) \tBatch Time 0.1118 (Average 0.1150) \t\n",
            "[Train] Epoch: [5][15/106]\tDice Loss 0.0051 (Average 0.0055) \tBatch Time 0.1102 (Average 0.1133) \t\n",
            "[Train] Epoch: [5][20/106]\tDice Loss 0.0052 (Average 0.0055) \tBatch Time 0.1105 (Average 0.1126) \t\n",
            "[Train] Epoch: [5][25/106]\tDice Loss 0.0057 (Average 0.0055) \tBatch Time 0.1098 (Average 0.1119) \t\n",
            "[Train] Epoch: [5][30/106]\tDice Loss 0.0051 (Average 0.0055) \tBatch Time 0.1080 (Average 0.1114) \t\n",
            "[Train] Epoch: [5][35/106]\tDice Loss 0.0052 (Average 0.0055) \tBatch Time 0.1087 (Average 0.1113) \t\n",
            "[Train] Epoch: [5][40/106]\tDice Loss 0.0055 (Average 0.0054) \tBatch Time 0.1123 (Average 0.1112) \t\n",
            "[Train] Epoch: [5][45/106]\tDice Loss 0.0055 (Average 0.0054) \tBatch Time 0.1085 (Average 0.1110) \t\n",
            "[Train] Epoch: [5][50/106]\tDice Loss 0.0065 (Average 0.0054) \tBatch Time 0.1114 (Average 0.1109) \t\n",
            "[Train] Epoch: [5][55/106]\tDice Loss 0.0051 (Average 0.0054) \tBatch Time 0.1120 (Average 0.1110) \t\n",
            "[Train] Epoch: [5][60/106]\tDice Loss 0.0052 (Average 0.0054) \tBatch Time 0.1113 (Average 0.1110) \t\n",
            "[Train] Epoch: [5][65/106]\tDice Loss 0.0047 (Average 0.0054) \tBatch Time 0.1114 (Average 0.1110) \t\n",
            "[Train] Epoch: [5][70/106]\tDice Loss 0.0051 (Average 0.0054) \tBatch Time 0.1090 (Average 0.1109) \t\n",
            "[Train] Epoch: [5][75/106]\tDice Loss 0.0055 (Average 0.0054) \tBatch Time 0.1123 (Average 0.1110) \t\n",
            "[Train] Epoch: [5][80/106]\tDice Loss 0.0053 (Average 0.0054) \tBatch Time 0.1102 (Average 0.1109) \t\n",
            "[Train] Epoch: [5][85/106]\tDice Loss 0.0053 (Average 0.0053) \tBatch Time 0.1115 (Average 0.1109) \t\n",
            "[Train] Epoch: [5][90/106]\tDice Loss 0.0056 (Average 0.0053) \tBatch Time 0.1121 (Average 0.1109) \t\n",
            "[Train] Epoch: [5][95/106]\tDice Loss 0.0050 (Average 0.0053) \tBatch Time 0.1101 (Average 0.1110) \t\n",
            "[Train] Epoch: [5][100/106]\tDice Loss 0.0049 (Average 0.0053) \tBatch Time 0.1100 (Average 0.1109) \t\n",
            "[Train] Epoch: [5][105/106]\tDice Loss 0.0049 (Average 0.0053) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "Validation\n",
            "[Val] Epoch: [5][5/19]\tDice Loss 0.0048 (Average 0.0050) \tBatch Time 0.0113 (Average 0.0124) \t\n",
            "[Val] Epoch: [5][10/19]\tDice Loss 0.0056 (Average 0.0050) \tBatch Time 0.0130 (Average 0.0125) \t\n",
            "[Val] Epoch: [5][15/19]\tDice Loss 0.0053 (Average 0.0051) \tBatch Time 0.0111 (Average 0.0123) \t\n",
            "******** Epoch [6/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [6][5/106]\tDice Loss 0.0057 (Average 0.0052) \tBatch Time 0.1095 (Average 0.1177) \t\n",
            "[Train] Epoch: [6][10/106]\tDice Loss 0.0045 (Average 0.0050) \tBatch Time 0.1069 (Average 0.1135) \t\n",
            "[Train] Epoch: [6][15/106]\tDice Loss 0.0048 (Average 0.0050) \tBatch Time 0.1100 (Average 0.1125) \t\n",
            "[Train] Epoch: [6][20/106]\tDice Loss 0.0047 (Average 0.0050) \tBatch Time 0.1099 (Average 0.1118) \t\n",
            "[Train] Epoch: [6][25/106]\tDice Loss 0.0049 (Average 0.0051) \tBatch Time 0.1059 (Average 0.1113) \t\n",
            "[Train] Epoch: [6][30/106]\tDice Loss 0.0049 (Average 0.0051) \tBatch Time 0.1121 (Average 0.1112) \t\n",
            "[Train] Epoch: [6][35/106]\tDice Loss 0.0047 (Average 0.0051) \tBatch Time 0.1116 (Average 0.1111) \t\n",
            "[Train] Epoch: [6][40/106]\tDice Loss 0.0051 (Average 0.0051) \tBatch Time 0.1122 (Average 0.1112) \t\n",
            "[Train] Epoch: [6][45/106]\tDice Loss 0.0046 (Average 0.0051) \tBatch Time 0.1112 (Average 0.1111) \t\n",
            "[Train] Epoch: [6][50/106]\tDice Loss 0.0049 (Average 0.0051) \tBatch Time 0.1122 (Average 0.1110) \t\n",
            "[Train] Epoch: [6][55/106]\tDice Loss 0.0050 (Average 0.0051) \tBatch Time 0.1101 (Average 0.1110) \t\n",
            "[Train] Epoch: [6][60/106]\tDice Loss 0.0049 (Average 0.0051) \tBatch Time 0.1098 (Average 0.1110) \t\n",
            "[Train] Epoch: [6][65/106]\tDice Loss 0.0050 (Average 0.0051) \tBatch Time 0.1099 (Average 0.1109) \t\n",
            "[Train] Epoch: [6][70/106]\tDice Loss 0.0048 (Average 0.0051) \tBatch Time 0.1126 (Average 0.1109) \t\n",
            "[Train] Epoch: [6][75/106]\tDice Loss 0.0049 (Average 0.0051) \tBatch Time 0.1111 (Average 0.1108) \t\n",
            "[Train] Epoch: [6][80/106]\tDice Loss 0.0055 (Average 0.0051) \tBatch Time 0.1114 (Average 0.1108) \t\n",
            "[Train] Epoch: [6][85/106]\tDice Loss 0.0053 (Average 0.0051) \tBatch Time 0.1115 (Average 0.1108) \t\n",
            "[Train] Epoch: [6][90/106]\tDice Loss 0.0051 (Average 0.0051) \tBatch Time 0.1113 (Average 0.1108) \t\n",
            "[Train] Epoch: [6][95/106]\tDice Loss 0.0051 (Average 0.0051) \tBatch Time 0.1102 (Average 0.1108) \t\n",
            "[Train] Epoch: [6][100/106]\tDice Loss 0.0050 (Average 0.0051) \tBatch Time 0.1101 (Average 0.1107) \t\n",
            "[Train] Epoch: [6][105/106]\tDice Loss 0.0044 (Average 0.0051) \tBatch Time 0.1112 (Average 0.1107) \t\n",
            "Validation\n",
            "[Val] Epoch: [6][5/19]\tDice Loss 0.0047 (Average 0.0048) \tBatch Time 0.0128 (Average 0.0133) \t\n",
            "[Val] Epoch: [6][10/19]\tDice Loss 0.0050 (Average 0.0048) \tBatch Time 0.0124 (Average 0.0130) \t\n",
            "[Val] Epoch: [6][15/19]\tDice Loss 0.0048 (Average 0.0049) \tBatch Time 0.0125 (Average 0.0128) \t\n",
            "******** Epoch [7/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [7][5/106]\tDice Loss 0.0051 (Average 0.0048) \tBatch Time 0.1088 (Average 0.1187) \t\n",
            "[Train] Epoch: [7][10/106]\tDice Loss 0.0041 (Average 0.0046) \tBatch Time 0.1095 (Average 0.1148) \t\n",
            "[Train] Epoch: [7][15/106]\tDice Loss 0.0050 (Average 0.0048) \tBatch Time 0.1112 (Average 0.1132) \t\n",
            "[Train] Epoch: [7][20/106]\tDice Loss 0.0045 (Average 0.0049) \tBatch Time 0.1118 (Average 0.1126) \t\n",
            "[Train] Epoch: [7][25/106]\tDice Loss 0.0048 (Average 0.0049) \tBatch Time 0.1081 (Average 0.1121) \t\n",
            "[Train] Epoch: [7][30/106]\tDice Loss 0.0050 (Average 0.0049) \tBatch Time 0.1111 (Average 0.1118) \t\n",
            "[Train] Epoch: [7][35/106]\tDice Loss 0.0048 (Average 0.0049) \tBatch Time 0.1105 (Average 0.1115) \t\n",
            "[Train] Epoch: [7][40/106]\tDice Loss 0.0053 (Average 0.0049) \tBatch Time 0.1099 (Average 0.1114) \t\n",
            "[Train] Epoch: [7][45/106]\tDice Loss 0.0048 (Average 0.0049) \tBatch Time 0.1109 (Average 0.1113) \t\n",
            "[Train] Epoch: [7][50/106]\tDice Loss 0.0054 (Average 0.0049) \tBatch Time 0.1087 (Average 0.1111) \t\n",
            "[Train] Epoch: [7][55/106]\tDice Loss 0.0046 (Average 0.0049) \tBatch Time 0.1102 (Average 0.1110) \t\n",
            "[Train] Epoch: [7][60/106]\tDice Loss 0.0047 (Average 0.0049) \tBatch Time 0.1086 (Average 0.1109) \t\n",
            "[Train] Epoch: [7][65/106]\tDice Loss 0.0051 (Average 0.0049) \tBatch Time 0.1087 (Average 0.1108) \t\n",
            "[Train] Epoch: [7][70/106]\tDice Loss 0.0048 (Average 0.0049) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [7][75/106]\tDice Loss 0.0052 (Average 0.0049) \tBatch Time 0.1109 (Average 0.1109) \t\n",
            "[Train] Epoch: [7][80/106]\tDice Loss 0.0052 (Average 0.0049) \tBatch Time 0.1089 (Average 0.1109) \t\n",
            "[Train] Epoch: [7][85/106]\tDice Loss 0.0046 (Average 0.0049) \tBatch Time 0.1111 (Average 0.1108) \t\n",
            "[Train] Epoch: [7][90/106]\tDice Loss 0.0049 (Average 0.0049) \tBatch Time 0.1117 (Average 0.1109) \t\n",
            "[Train] Epoch: [7][95/106]\tDice Loss 0.0050 (Average 0.0049) \tBatch Time 0.1116 (Average 0.1108) \t\n",
            "[Train] Epoch: [7][100/106]\tDice Loss 0.0045 (Average 0.0049) \tBatch Time 0.1123 (Average 0.1108) \t\n",
            "[Train] Epoch: [7][105/106]\tDice Loss 0.0043 (Average 0.0048) \tBatch Time 0.1100 (Average 0.1108) \t\n",
            "Validation\n",
            "[Val] Epoch: [7][5/19]\tDice Loss 0.0045 (Average 0.0045) \tBatch Time 0.0116 (Average 0.0123) \t\n",
            "[Val] Epoch: [7][10/19]\tDice Loss 0.0047 (Average 0.0045) \tBatch Time 0.0115 (Average 0.0122) \t\n",
            "[Val] Epoch: [7][15/19]\tDice Loss 0.0044 (Average 0.0044) \tBatch Time 0.0122 (Average 0.0122) \t\n",
            "******** Epoch [8/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [8][5/106]\tDice Loss 0.0045 (Average 0.0046) \tBatch Time 0.1108 (Average 0.1210) \t\n",
            "[Train] Epoch: [8][10/106]\tDice Loss 0.0045 (Average 0.0046) \tBatch Time 0.1101 (Average 0.1153) \t\n",
            "[Train] Epoch: [8][15/106]\tDice Loss 0.0046 (Average 0.0046) \tBatch Time 0.1104 (Average 0.1133) \t\n",
            "[Train] Epoch: [8][20/106]\tDice Loss 0.0043 (Average 0.0045) \tBatch Time 0.1084 (Average 0.1124) \t\n",
            "[Train] Epoch: [8][25/106]\tDice Loss 0.0040 (Average 0.0044) \tBatch Time 0.1100 (Average 0.1120) \t\n",
            "[Train] Epoch: [8][30/106]\tDice Loss 0.0040 (Average 0.0043) \tBatch Time 0.1100 (Average 0.1116) \t\n",
            "[Train] Epoch: [8][35/106]\tDice Loss 0.0036 (Average 0.0043) \tBatch Time 0.1106 (Average 0.1114) \t\n",
            "[Train] Epoch: [8][40/106]\tDice Loss 0.0039 (Average 0.0042) \tBatch Time 0.1087 (Average 0.1111) \t\n",
            "[Train] Epoch: [8][45/106]\tDice Loss 0.0044 (Average 0.0041) \tBatch Time 0.1097 (Average 0.1110) \t\n",
            "[Train] Epoch: [8][50/106]\tDice Loss 0.0034 (Average 0.0041) \tBatch Time 0.1082 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][55/106]\tDice Loss 0.0034 (Average 0.0040) \tBatch Time 0.1099 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][60/106]\tDice Loss 0.0034 (Average 0.0040) \tBatch Time 0.1108 (Average 0.1108) \t\n",
            "[Train] Epoch: [8][65/106]\tDice Loss 0.0036 (Average 0.0040) \tBatch Time 0.1116 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][70/106]\tDice Loss 0.0038 (Average 0.0039) \tBatch Time 0.1117 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][75/106]\tDice Loss 0.0038 (Average 0.0039) \tBatch Time 0.1100 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][80/106]\tDice Loss 0.0038 (Average 0.0039) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][85/106]\tDice Loss 0.0030 (Average 0.0039) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [8][90/106]\tDice Loss 0.0035 (Average 0.0038) \tBatch Time 0.1124 (Average 0.1108) \t\n",
            "[Train] Epoch: [8][95/106]\tDice Loss 0.0036 (Average 0.0038) \tBatch Time 0.1096 (Average 0.1108) \t\n",
            "[Train] Epoch: [8][100/106]\tDice Loss 0.0040 (Average 0.0038) \tBatch Time 0.1082 (Average 0.1108) \t\n",
            "[Train] Epoch: [8][105/106]\tDice Loss 0.0034 (Average 0.0038) \tBatch Time 0.1113 (Average 0.1107) \t\n",
            "Validation\n",
            "[Val] Epoch: [8][5/19]\tDice Loss 0.0031 (Average 0.0033) \tBatch Time 0.0118 (Average 0.0121) \t\n",
            "[Val] Epoch: [8][10/19]\tDice Loss 0.0034 (Average 0.0033) \tBatch Time 0.0142 (Average 0.0125) \t\n",
            "[Val] Epoch: [8][15/19]\tDice Loss 0.0034 (Average 0.0033) \tBatch Time 0.0125 (Average 0.0124) \t\n",
            "******** Epoch [9/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [9][5/106]\tDice Loss 0.0037 (Average 0.0034) \tBatch Time 0.1107 (Average 0.1157) \t\n",
            "[Train] Epoch: [9][10/106]\tDice Loss 0.0034 (Average 0.0035) \tBatch Time 0.1114 (Average 0.1130) \t\n",
            "[Train] Epoch: [9][15/106]\tDice Loss 0.0036 (Average 0.0035) \tBatch Time 0.1110 (Average 0.1120) \t\n",
            "[Train] Epoch: [9][20/106]\tDice Loss 0.0035 (Average 0.0035) \tBatch Time 0.1096 (Average 0.1111) \t\n",
            "[Train] Epoch: [9][25/106]\tDice Loss 0.0038 (Average 0.0034) \tBatch Time 0.1095 (Average 0.1106) \t\n",
            "[Train] Epoch: [9][30/106]\tDice Loss 0.0041 (Average 0.0035) \tBatch Time 0.1089 (Average 0.1104) \t\n",
            "[Train] Epoch: [9][35/106]\tDice Loss 0.0030 (Average 0.0034) \tBatch Time 0.1096 (Average 0.1104) \t\n",
            "[Train] Epoch: [9][40/106]\tDice Loss 0.0033 (Average 0.0034) \tBatch Time 0.1101 (Average 0.1103) \t\n",
            "[Train] Epoch: [9][45/106]\tDice Loss 0.0031 (Average 0.0034) \tBatch Time 0.1057 (Average 0.1101) \t\n",
            "[Train] Epoch: [9][50/106]\tDice Loss 0.0033 (Average 0.0034) \tBatch Time 0.1088 (Average 0.1101) \t\n",
            "[Train] Epoch: [9][55/106]\tDice Loss 0.0031 (Average 0.0034) \tBatch Time 0.1112 (Average 0.1100) \t\n",
            "[Train] Epoch: [9][60/106]\tDice Loss 0.0031 (Average 0.0034) \tBatch Time 0.1100 (Average 0.1100) \t\n",
            "[Train] Epoch: [9][65/106]\tDice Loss 0.0034 (Average 0.0034) \tBatch Time 0.1102 (Average 0.1100) \t\n",
            "[Train] Epoch: [9][70/106]\tDice Loss 0.0036 (Average 0.0034) \tBatch Time 0.1084 (Average 0.1100) \t\n",
            "[Train] Epoch: [9][75/106]\tDice Loss 0.0039 (Average 0.0034) \tBatch Time 0.1079 (Average 0.1099) \t\n",
            "[Train] Epoch: [9][80/106]\tDice Loss 0.0036 (Average 0.0034) \tBatch Time 0.1110 (Average 0.1099) \t\n",
            "[Train] Epoch: [9][85/106]\tDice Loss 0.0033 (Average 0.0034) \tBatch Time 0.1083 (Average 0.1099) \t\n",
            "[Train] Epoch: [9][90/106]\tDice Loss 0.0032 (Average 0.0034) \tBatch Time 0.1100 (Average 0.1099) \t\n",
            "[Train] Epoch: [9][95/106]\tDice Loss 0.0034 (Average 0.0034) \tBatch Time 0.1096 (Average 0.1099) \t\n",
            "[Train] Epoch: [9][100/106]\tDice Loss 0.0032 (Average 0.0034) \tBatch Time 0.1081 (Average 0.1098) \t\n",
            "[Train] Epoch: [9][105/106]\tDice Loss 0.0030 (Average 0.0034) \tBatch Time 0.1062 (Average 0.1097) \t\n",
            "Validation\n",
            "[Val] Epoch: [9][5/19]\tDice Loss 0.0034 (Average 0.0033) \tBatch Time 0.0123 (Average 0.0127) \t\n",
            "[Val] Epoch: [9][10/19]\tDice Loss 0.0033 (Average 0.0033) \tBatch Time 0.0119 (Average 0.0127) \t\n",
            "[Val] Epoch: [9][15/19]\tDice Loss 0.0035 (Average 0.0033) \tBatch Time 0.0120 (Average 0.0125) \t\n",
            "******** Epoch [10/11]  ********\n",
            "Test_session_10.11 13h12\n",
            "Training\n",
            "[Train] Epoch: [10][5/106]\tDice Loss 0.0035 (Average 0.0034) \tBatch Time 0.1110 (Average 0.1196) \t\n",
            "[Train] Epoch: [10][10/106]\tDice Loss 0.0039 (Average 0.0034) \tBatch Time 0.1095 (Average 0.1148) \t\n",
            "[Train] Epoch: [10][15/106]\tDice Loss 0.0035 (Average 0.0033) \tBatch Time 0.1112 (Average 0.1133) \t\n",
            "[Train] Epoch: [10][20/106]\tDice Loss 0.0030 (Average 0.0033) \tBatch Time 0.1098 (Average 0.1123) \t\n",
            "[Train] Epoch: [10][25/106]\tDice Loss 0.0034 (Average 0.0033) \tBatch Time 0.1084 (Average 0.1118) \t\n",
            "[Train] Epoch: [10][30/106]\tDice Loss 0.0032 (Average 0.0033) \tBatch Time 0.1098 (Average 0.1113) \t\n",
            "[Train] Epoch: [10][35/106]\tDice Loss 0.0038 (Average 0.0033) \tBatch Time 0.1114 (Average 0.1111) \t\n",
            "[Train] Epoch: [10][40/106]\tDice Loss 0.0033 (Average 0.0033) \tBatch Time 0.1111 (Average 0.1111) \t\n",
            "[Train] Epoch: [10][45/106]\tDice Loss 0.0032 (Average 0.0033) \tBatch Time 0.1097 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][50/106]\tDice Loss 0.0031 (Average 0.0033) \tBatch Time 0.1115 (Average 0.1110) \t\n",
            "[Train] Epoch: [10][55/106]\tDice Loss 0.0032 (Average 0.0033) \tBatch Time 0.1116 (Average 0.1110) \t\n",
            "[Train] Epoch: [10][60/106]\tDice Loss 0.0029 (Average 0.0033) \tBatch Time 0.1099 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][65/106]\tDice Loss 0.0034 (Average 0.0033) \tBatch Time 0.1113 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][70/106]\tDice Loss 0.0032 (Average 0.0033) \tBatch Time 0.1110 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][75/106]\tDice Loss 0.0033 (Average 0.0033) \tBatch Time 0.1101 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][80/106]\tDice Loss 0.0035 (Average 0.0033) \tBatch Time 0.1098 (Average 0.1108) \t\n",
            "[Train] Epoch: [10][85/106]\tDice Loss 0.0032 (Average 0.0033) \tBatch Time 0.1116 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][90/106]\tDice Loss 0.0031 (Average 0.0033) \tBatch Time 0.1112 (Average 0.1108) \t\n",
            "[Train] Epoch: [10][95/106]\tDice Loss 0.0029 (Average 0.0033) \tBatch Time 0.1118 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][100/106]\tDice Loss 0.0032 (Average 0.0033) \tBatch Time 0.1119 (Average 0.1109) \t\n",
            "[Train] Epoch: [10][105/106]\tDice Loss 0.0030 (Average 0.0033) \tBatch Time 0.1086 (Average 0.1109) \t\n",
            "Validation\n",
            "[Val] Epoch: [10][5/19]\tDice Loss 0.0032 (Average 0.0032) \tBatch Time 0.0131 (Average 0.0129) \t\n",
            "[Val] Epoch: [10][10/19]\tDice Loss 0.0029 (Average 0.0031) \tBatch Time 0.0125 (Average 0.0126) \t\n",
            "[Val] Epoch: [10][15/19]\tDice Loss 0.0028 (Average 0.0032) \tBatch Time 0.0123 (Average 0.0125) \t\n"
          ]
        }
      ],
      "source": [
        "model = \"\"\"Complete here\"\"\" # Create model\n",
        "model.cuda() # move model to GPU\n",
        "\n",
        "criterion = \"\"\"Complete here\"\"\" # Choose loss function\n",
        "optimizer = \"\"\"Complete here\"\"\" # Choose optimizer\n",
        "\n",
        "# Keep logs of training metrics. To visualize with tensorbard.\n",
        "log_dir = tensorboard_folder + session_name + '/'\n",
        "if not os.path.isdir(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "writer = torch.utils.tensorboard.SummaryWriter(log_dir)\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n",
        "    print(session_name)\n",
        "\n",
        "    # train for one epoch\n",
        "    model.train()\n",
        "    print('Training')\n",
        "    train_loop(train_loader_data_augment, model, criterion,\n",
        "               optimizer, writer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    print('Validation')\n",
        "    with torch.no_grad():  # Don't compute gradients\n",
        "        model.eval()       # Deactivate any BarchNormalization or Dropout layer\n",
        "        val_loss = train_loop(val_loader_data_augment, model, criterion,\n",
        "                              optimizer, writer, epoch)\n",
        "    # Save model and otpimizer states\n",
        "    # Saving the optimizer state allows to do further fine tuning later.\n",
        "    if save_model and epoch % save_frequency == 0:\n",
        "        save_checkpoint({'epoch': epoch,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                         'val_loss': val_loss,\n",
        "                         'optimizer': optimizer.state_dict()}, model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved checkpoint\n",
        "checkpoint = torch.load('model_checkpoint_1.pth')\n",
        "\n",
        "# Load the state_dict into the model\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xfMg6ZI__HT"
      },
      "source": [
        "## 7.c. Evaluation du modèle\n",
        "\n",
        "Exécutez le code suivant pour évaluer le modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "PESqk1-0_9f-",
        "outputId": "cc915121-0f7a-4e03-d2c8-f71d1de89208"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3276it [00:51, 63.28it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mask shape: (78, 4, 96, 96)\n",
            "Resized mask shape: (155, 240, 240)\n"
          ]
        }
      ],
      "source": [
        "test_path = original_data_path\n",
        "patients = [os.path.basename(p) for p in glob(test_path + \"*\")]\n",
        "patient = patients[0]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader_data_augment, model, batch_size=batch_size)\n",
        "\n",
        "\n",
        "predict_mask = reconstruct_patient(preds, patient)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Model prediction\")\n",
        "plt.imshow(np.argmax(predict_mask[50, ...], axis=0))\n",
        "plt.show()\n",
        "\n",
        "print(\"Mask shape:\", predict_mask.shape)\n",
        "\n",
        "predict_mask = get_mask2original_shape(predict_mask)\n",
        "print(\"Resized mask shape:\", predict_mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gWzEu7zCXqj"
      },
      "outputs": [],
      "source": [
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model, batch_size=batch_size)\n",
        "\n",
        "for patient in patients:\n",
        "    # Path to original image\n",
        "    patient_folder = os.path.join(test_path,patient)\n",
        "    # Open image\n",
        "    orig_image = sitk.ReadImage(os.path.join(patient_folder,\n",
        "                                            patient  + '_seg.nii.gz' ))\n",
        "    # Convert image to numpy array\n",
        "    orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "    # Reconstruct the whole patient predicted mask\n",
        "    predict_mask = reconstruct_patient(preds, patient)\n",
        "    predict_mask = get_mask2original_shape(predict_mask)\n",
        "\n",
        "    print('*********** {} ***********'.format(patient))\n",
        "    scores = evalAllSample(predict_mask, orig_mask)\n",
        "    print(scores)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    wt_dice_list.append(scores.loc['Dice', 'wt'])\n",
        "    et_dice_list.append(scores.loc['Dice', 'et'])\n",
        "    tc_dice_list.append(scores.loc['Dice', 'tc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crUzG4gYCaaC"
      },
      "outputs": [],
      "source": [
        "print('Whole Tumor Dice : {:.2f}'.format(np.mean(wt_dice_list)))\n",
        "print('Tumor Core Dice : {:.2f}'.format(np.mean(et_dice_list)))\n",
        "print('Enhancing Tumor Dice : {:.2f}'.format(np.mean(tc_dice_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **8. Load an architecture from GitHub**\n",
        "\n",
        "In the following code you will learn how to get an architure directly from a github repository.\n",
        "\n",
        "The github that we are cloning is [here](https://github.com/soniamartinot/BraTs_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'BraTs_models'...\n",
            "remote: Enumerating objects: 1322, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 1322 (delta 30), reused 47 (delta 30), pack-reused 1273 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1322/1322), 18.80 MiB | 2.65 MiB/s, done.\n",
            "Resolving deltas: 100% (826/826), done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/soniamartinot/BraTs_models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16, 4, 128, 128])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from BraTs_models.pytorch.models.deeplab import Deeplab_V3_Plus\n",
        "\n",
        "model = Deeplab_V3_Plus(class_num=4, n_input_channels=4, drop_rate=0)\n",
        "x = torch.rand(16, 4, 128, 128)\n",
        "model(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Deeplab_V3_Plus(\n",
              "  (resnet): ResNet(\n",
              "    (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): Dropout2d(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): Dropout2d(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (5): BasicBlock(\n",
              "        (dp): Dropout2d(p=0, inplace=False)\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (low_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (atr_conv1): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (atr_conv2): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (atr_conv3): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (atr_conv4): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv0): Sequential(\n",
              "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout2d(p=0, inplace=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (dp): Dropout2d(p=0, inplace=False)\n",
              "    (conv1): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (atr_conv1): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (atr_conv2): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (atr_conv3): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    (conv2): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv_cat): Sequential(\n",
              "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Dropout2d(p=0, inplace=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout2d(p=0, inplace=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout2d(p=0, inplace=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout2d(p=0, inplace=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout2d(p=0, inplace=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv5): Sequential(\n",
              "    (0): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout2d(p=0, inplace=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 5/106 [00:28<09:26,  5.61s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[0;32m/var/folders/jf/by73pf5n03nb93hx_qcks6wc0000gp/T/ipykernel_20380/3874471646.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      9\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     13\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/var/folders/jf/by73pf5n03nb93hx_qcks6wc0000gp/T/ipykernel_20380/3928264069.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(loader, model, criterion, optimizer, writer, epoch)\u001b[0m\n",
            "\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_time_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Take variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     13\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mirms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[1;32m   1192\u001b[0m                         \u001b[0mlast_print_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1193\u001b[0m                         \u001b[0mlast_print_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1194\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[1;32m    626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    632\u001b[0m             if self._dataset_kind == _DatasetKind.Iterable and \\\n",
            "\u001b[1;32m    633\u001b[0m                     self._IterableDataset_len_called is not None and \\\n",
            "\n",
            "\u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n",
            "\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/var/folders/jf/by73pf5n03nb93hx_qcks6wc0000gp/T/ipykernel_20380/1736924339.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, idx)\u001b[0m\n",
            "\u001b[1;32m     15\u001b[0m         \u001b[0;34m'Get a patient given idx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     16\u001b[0m         \u001b[0mpatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Load the patient's modalities and segmentation masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mirm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mirm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Apply data transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/var/folders/jf/by73pf5n03nb93hx_qcks6wc0000gp/T/ipykernel_20380/1736924339.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, ID)\u001b[0m\n",
            "\u001b[1;32m     33\u001b[0m         \u001b[0mirm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodalities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     35\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{patient}_{modality}_z_{z_slice}.nii.gz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     36\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mirm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_sitk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mirm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Get the segmentation mask for the given slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/var/folders/jf/by73pf5n03nb93hx_qcks6wc0000gp/T/ipykernel_20380/3605636057.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(path)\u001b[0m\n",
            "\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_sitk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n",
            "\u001b[1;32m    380\u001b[0m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetFileNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    382\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    383\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[1;32m   8498\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mitk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mConvertPixelBuffer\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   8499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   8500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   8501\u001b[0m         \"\"\"\n",
            "\u001b[0;32m-> 8502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "learning_curves = {\"train\": [],\n",
        "                   \"validation\": []}\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    # print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # train for one epoch\n",
        "    train_loss_ = train_loop(train_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "\n",
        "    # evaluate on validation set\n",
        "    with torch.no_grad():   # Disable gradient computation (faster and saves memory)\n",
        "        model.eval()        # Disable Dropout and BatchNormalization\n",
        "        val_loss = train_loop(val_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    learning_curves['train'] += [train_loss_.item()]\n",
        "    learning_curves['validation'] += [val_loss.item()]\n",
        "\n",
        "    # Visualisez les courbes d'apprentissage\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot(learning_curves['train'], '-*', label=\"train\")\n",
        "    plt.plot(learning_curves['validation'], '--*', label=\"validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss value\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Learning curves - Epoch: {epoch}\")\n",
        "    plt.show()\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # if save_model and epoch % save_frequency == 0:\n",
        "        # save_checkpoint({'epoch': epoch,\n",
        "        #                 'state_dict': model.state_dict(),\n",
        "        #                  'val_loss': val_loss,\n",
        "        #                  'optimizer': optimizer.state_dict()}, model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved checkpoint\n",
        "checkpoint = torch.load('model_checkpoint_2.pth')\n",
        "\n",
        "# Load the state_dict into the model\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 23/3276 [00:03<08:16,  6.55it/s] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[83], line 7\u001b[0m\n",
            "\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
            "\u001b[0;32m----> 7\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patient \u001b[38;5;129;01min\u001b[39;00m patients:\n",
            "\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Path to original image\u001b[39;00m\n",
            "\u001b[1;32m     11\u001b[0m     patient_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_path,patient)\n",
            "\n",
            "Cell \u001b[0;32mIn[57], line 13\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(loader, model, batch_size)\u001b[0m\n",
            "\u001b[1;32m     10\u001b[0m batch_patient_names, batch_z_slices \u001b[38;5;241m=\u001b[39m patients[\u001b[38;5;241m0\u001b[39m], patients[\u001b[38;5;241m1\u001b[39m]\n",
            "\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n",
            "\u001b[0;32m---> 13\u001b[0m pred_masks \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mirms\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Put the predictions in a dictionnary with one key being the\u001b[39;00m\n",
            "\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# patient and the z slice\u001b[39;00m\n",
            "\u001b[1;32m     17\u001b[0m n_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pred_masks)\n",
            "\n",
            "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
            "\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/Downloads/BraTs_models/pytorch/models/deeplab.py:286\u001b[0m, in \u001b[0;36mDeeplab_V3_Plus.forward\u001b[0;34m(self, x)\u001b[0m\n",
            "\u001b[1;32m    284\u001b[0m y, low_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet(x)\n",
            "\u001b[1;32m    285\u001b[0m low_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv0(low_y)\n",
            "\u001b[0;32m--> 286\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    287\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([low_y, y], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[1;32m    288\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(y)\n",
            "\n",
            "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
            "\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/Downloads/BraTs_models/pytorch/models/deeplab.py:262\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n",
            "\u001b[1;32m    260\u001b[0m y5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
            "\u001b[1;32m    261\u001b[0m y5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(y5)\n",
            "\u001b[0;32m--> 262\u001b[0m y5 \u001b[38;5;241m=\u001b[39m \u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    264\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y1, y2, y3, y4], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[1;32m    265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_cat(y)\n",
            "\n",
            "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/functional.py:4087\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n",
            "\u001b[1;32m   4081\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda:\n",
            "\u001b[1;32m   4082\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001b[39;00m\n",
            "\u001b[1;32m   4083\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n",
            "\u001b[1;32m   4084\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n",
            "\u001b[1;32m   4085\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_upsample_linear_vec(\n",
            "\u001b[1;32m   4086\u001b[0m                 \u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n",
            "\u001b[0;32m-> 4087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_bilinear2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = predict(test_loader, model, batch_size=batch_size)\n",
        "\n",
        "for patient in patients:\n",
        "    # Path to original image\n",
        "    patient_folder = os.path.join(test_path,patient)\n",
        "    # Open image\n",
        "    orig_image = sitk.ReadImage(os.path.join(patient_folder,\n",
        "                                            patient  + '_seg.nii.gz' ))\n",
        "    # Convert image to numpy array\n",
        "    orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "    # Reconstruct the whole patient predicted mask\n",
        "    predict_mask = reconstruct_patient(preds, patient)\n",
        "    predict_mask = get_mask2original_shape(predict_mask)\n",
        "\n",
        "    print('*********** {} ***********'.format(patient))\n",
        "    scores = evalAllSample(predict_mask, orig_mask)\n",
        "    print(scores)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    wt_dice_list.append(scores.loc['Dice', 'wt'])\n",
        "    et_dice_list.append(scores.loc['Dice', 'et'])\n",
        "    tc_dice_list.append(scores.loc['Dice', 'tc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "U5zrwq0EFT-S"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
